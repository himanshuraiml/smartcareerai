export const cloudEngineerQuestions = [
  // ===== EASY (30 questions) =====
  { questionText: "What is cloud computing and what are its main service models?", idealAnswer: "Cloud computing delivers computing resources over the internet on-demand. Service models: IaaS (Infrastructure as a Service) — virtual servers, storage, networking (EC2, Azure VMs). PaaS (Platform as a Service) — managed runtime for deploying apps (Heroku, App Engine, Elastic Beanstalk). SaaS (Software as a Service) — complete applications (Gmail, Salesforce). Each layer abstracts more infrastructure management from the user.", category: "Fundamentals", difficulty: "EASY" as const, tags: ["cloud", "iaas", "paas", "saas"] },
  { questionText: "What are the main cloud providers and their key services?", idealAnswer: "AWS (largest market share): EC2 (compute), S3 (storage), RDS (database), Lambda (serverless). Azure (Microsoft): Virtual Machines, Blob Storage, Azure SQL, Functions. GCP (Google): Compute Engine, Cloud Storage, Cloud SQL, Cloud Functions. All offer: VPCs, load balancers, container services (EKS/AKS/GKE), managed databases, serverless, monitoring. Choose based on existing tech stack, pricing, specific service strengths, and compliance requirements.", category: "Fundamentals", difficulty: "EASY" as const, tags: ["aws", "azure", "gcp"] },
  { questionText: "What is a Virtual Private Cloud (VPC)?", idealAnswer: "A VPC is a logically isolated network within the cloud. You define: IP address range (CIDR block), subnets (public/private), route tables, internet gateways, NAT gateways. Public subnets have internet access via internet gateway; private subnets access internet via NAT gateway. Security: security groups (instance-level firewall) and NACLs (subnet-level). VPCs enable network isolation between environments and applications.", category: "Networking", difficulty: "EASY" as const, tags: ["vpc", "networking", "isolation"] },
  { questionText: "What is object storage and how does S3 work?", idealAnswer: "Object storage stores data as objects (file + metadata) in flat namespaces (buckets), not hierarchical file systems. S3: unlimited storage, 99.999999999% durability, accessed via HTTP API. Features: versioning, lifecycle policies (transition to cheaper tiers), encryption, access policies. Storage classes: Standard (frequent access), IA (infrequent), Glacier (archive). Use for: backups, static websites, data lakes, media files. Not for: databases, frequently modified files.", category: "Storage", difficulty: "EASY" as const, tags: ["s3", "object-storage", "storage"] },
  { questionText: "What is a managed database service?", idealAnswer: "Managed databases handle operational tasks: provisioning, patching, backups, replication, scaling, failover. Examples: AWS RDS (PostgreSQL, MySQL), Aurora, DynamoDB, Azure SQL, Cloud SQL. Benefits: reduced ops overhead, automated backups, multi-AZ failover, read replicas. Trade-offs: less control, vendor lock-in, potentially higher cost at scale vs self-managed. Choose managed unless you need specific configurations or optimizations that managed services don't support.", category: "Databases", difficulty: "EASY" as const, tags: ["rds", "managed-database", "cloud"] },
  { questionText: "What is serverless computing?", idealAnswer: "Serverless runs code without managing servers — the cloud provider handles scaling, patching, and availability. You pay per execution (no idle cost). Services: AWS Lambda, Azure Functions, Google Cloud Functions. Benefits: zero server management, auto-scaling from 0 to thousands, pay-per-use. Limitations: cold starts, execution time limits (15 min Lambda), stateless, vendor lock-in. Use for: event handlers, API endpoints, scheduled tasks, data processing. Not ideal for long-running or stateful workloads.", category: "Compute", difficulty: "EASY" as const, tags: ["serverless", "lambda", "functions"] },
  { questionText: "What are availability zones and regions?", idealAnswer: "A region is a geographic area with multiple isolated data centers (e.g., us-east-1, eu-west-1). Availability Zones (AZs) are physically separate data centers within a region, connected by low-latency links. Deploy across multiple AZs for high availability — if one AZ fails, others continue. Deploy across regions for disaster recovery and low latency to global users. Each AZ has independent power, cooling, and networking.", category: "Infrastructure", difficulty: "EASY" as const, tags: ["availability-zones", "regions", "high-availability"] },
  { questionText: "What is an EC2 instance?", idealAnswer: "EC2 (Elastic Compute Cloud) is AWS's virtual server service. Choose: instance type (CPU, memory, storage optimized), AMI (OS image), storage (EBS volumes), security group, and key pair. Instance families: t3 (general purpose, burstable), m5 (general), c5 (compute optimized), r5 (memory), g4 (GPU). Pricing: On-Demand (hourly), Reserved (1-3 year commitment, cheaper), Spot (up to 90% off, can be interrupted). Launch via console, CLI, Terraform, or auto-scaling groups.", category: "Compute", difficulty: "EASY" as const, tags: ["ec2", "compute", "aws"] },
  { questionText: "What is a CDN and how does CloudFront work?", idealAnswer: "A CDN (Content Delivery Network) caches content at edge locations close to users, reducing latency. CloudFront (AWS): distributes static/dynamic content from origin (S3, EC2, ALB) via 400+ edge locations worldwide. Features: HTTPS, custom domains, caching rules, origin failover, Lambda@Edge for edge computing. Benefits: faster page loads, reduced origin server load, DDoS protection. Use for: static assets (images, CSS, JS), API caching, video streaming.", category: "Networking", difficulty: "EASY" as const, tags: ["cdn", "cloudfront", "caching"] },
  { questionText: "What is IAM and how does it work?", idealAnswer: "IAM (Identity and Access Management) controls who can access cloud resources and what they can do. Components: Users (people), Groups (collections of users), Roles (assumed by services), Policies (JSON documents defining permissions). Best practices: least privilege (minimum necessary permissions), use roles over access keys, enable MFA, regular access reviews, don't use root account. IAM policies specify: Effect (Allow/Deny), Action (s3:GetObject), Resource (specific ARN).", category: "Security", difficulty: "EASY" as const, tags: ["iam", "security", "access-control"] },
  { questionText: "What is auto-scaling in the cloud?", idealAnswer: "Auto-scaling automatically adjusts compute capacity based on demand. AWS Auto Scaling Groups: define min/max instances, scaling policies based on metrics (CPU > 70% → add instance). Types: target tracking (maintain metric at value), step scaling (add N instances per threshold), scheduled (known traffic patterns). Also: Kubernetes HPA for pods, Lambda scales automatically. Benefits: handle traffic spikes, reduce costs during low traffic, maintain availability. Always set maximum limits to prevent runaway costs.", category: "Compute", difficulty: "EASY" as const, tags: ["auto-scaling", "elasticity", "cloud"] },
  { questionText: "What is a load balancer in AWS?", idealAnswer: "AWS offers three load balancers: ALB (Application Load Balancer): Layer 7, HTTP/HTTPS, path-based routing, host-based routing, WebSocket support. NLB (Network Load Balancer): Layer 4, ultra-low latency, static IP, TCP/UDP. CLB (Classic, legacy): both L4/L7, being replaced by ALB/NLB. Features: health checks, SSL termination, access logs, integration with auto-scaling. Use ALB for web applications, NLB for non-HTTP protocols or extreme performance needs.", category: "Networking", difficulty: "EASY" as const, tags: ["load-balancer", "alb", "networking"] },
  { questionText: "What is Infrastructure as Code and why use Terraform?", idealAnswer: "IaC defines infrastructure in code files instead of manual configuration. Terraform: multi-cloud support, declarative HCL syntax, plan before apply, state management, module reuse. Workflow: write .tf files → terraform init → terraform plan (preview) → terraform apply (create). Benefits: reproducible environments, version controlled, code review for infrastructure changes, disaster recovery. Store state remotely (S3 + DynamoDB lock). Alternative: CloudFormation (AWS-only), Pulumi (programming languages).", category: "IaC", difficulty: "EASY" as const, tags: ["terraform", "iac", "automation"] },
  { questionText: "What is DNS in the cloud (Route 53)?", idealAnswer: "Route 53 is AWS's DNS service. Features: domain registration, DNS hosting, health checking, traffic routing. Routing policies: Simple (single record), Weighted (A/B testing, gradual migration), Latency-based (route to nearest region), Failover (active-passive), Geolocation (route by user location). Health checks monitor endpoint health and trigger DNS failover. Alias records: point to AWS resources (ALB, CloudFront) without a CNAME charge. Combine with CloudFront for global low-latency delivery.", category: "Networking", difficulty: "EASY" as const, tags: ["route53", "dns", "networking"] },
  { questionText: "What is cloud monitoring and what tools exist?", idealAnswer: "Cloud monitoring tracks resource health, performance, and costs. AWS CloudWatch: metrics, logs, alarms, dashboards. Azure Monitor: similar capabilities. GCP: Cloud Monitoring (Stackdriver). Third-party: Datadog, New Relic, Grafana Cloud. Key metrics: CPU utilization, memory, disk I/O, network, error rates, latency. Set alarms for: high CPU, elevated error rates, low disk space. CloudWatch Logs: centralized log storage and analysis. Cost monitoring: AWS Cost Explorer, billing alerts.", category: "Monitoring", difficulty: "EASY" as const, tags: ["cloudwatch", "monitoring", "observability"] },
  { questionText: "What is a security group vs a NACL?", idealAnswer: "Security Groups: instance-level firewall, stateful (return traffic automatically allowed), allow rules only. NACLs (Network Access Control Lists): subnet-level, stateless (must explicitly allow both inbound and outbound), allow and deny rules, processed in order. Use security groups as primary defense (specific to each resource), NACLs as an additional subnet-level safeguard. Best practice: restrict security groups to minimal needed ports and sources, deny all by default.", category: "Security", difficulty: "EASY" as const, tags: ["security-groups", "nacl", "networking"] },
  { questionText: "What is EBS and how does it differ from S3?", idealAnswer: "EBS (Elastic Block Store): block storage attached to EC2 instances like a virtual hard drive. Low-latency, supports file systems, used for OS, databases, applications. Types: gp3 (general purpose SSD), io2 (high IOPS), st1 (throughput HDD). S3: object storage accessed via HTTP API, unlimited capacity, high durability. Use EBS for: server storage, databases. Use S3 for: backups, static files, data lakes. EBS is per-AZ; S3 is regional. EBS snapshots stored in S3 for backup.", category: "Storage", difficulty: "EASY" as const, tags: ["ebs", "s3", "storage"] },
  { questionText: "What is a container service in the cloud?", idealAnswer: "Cloud container services run Docker containers at scale. AWS: ECS (AWS-native), EKS (managed Kubernetes), Fargate (serverless containers). Azure: AKS (managed Kubernetes), Container Instances. GCP: GKE (managed Kubernetes), Cloud Run (serverless containers). ECS is simpler but AWS-specific. EKS/AKS/GKE run standard Kubernetes. Fargate/Cloud Run eliminate node management. Choose based on: Kubernetes expertise, portability needs, operational simplicity preference.", category: "Compute", difficulty: "EASY" as const, tags: ["ecs", "eks", "containers"] },
  { questionText: "What is the Shared Responsibility Model?", idealAnswer: "Cloud security responsibility is shared between the provider and customer. Provider responsible for: physical data centers, hardware, hypervisor, managed service infrastructure (security OF the cloud). Customer responsible for: OS patches (IaaS), application security, IAM configuration, data encryption, network configuration, firewall rules (security IN the cloud). The line shifts by service model: IaaS (customer manages most) → PaaS → SaaS (provider manages most). Always understand what you're responsible for.", category: "Security", difficulty: "EASY" as const, tags: ["shared-responsibility", "security", "cloud"] },
  { questionText: "What is a message queue service in the cloud?", idealAnswer: "Cloud message queues decouple services for async communication. AWS SQS: fully managed queue, standard (at-least-once, best-effort ordering) or FIFO (exactly-once, ordered). AWS SNS: pub/sub notification service. Azure Service Bus, GCP Pub/Sub. Use for: decoupling microservices, handling traffic spikes, reliable async processing. Features: dead-letter queues (failed messages), visibility timeout, retry policies. Cost: pay per message. Often combined with Lambda for serverless event processing.", category: "Messaging", difficulty: "EASY" as const, tags: ["sqs", "sns", "messaging"] },
  { questionText: "What is cloud cost management?", idealAnswer: "Cloud costs can spiral without governance. Key practices: (1) Tagging: mandatory tags for cost allocation per team/project, (2) Budgets: set monthly budgets with alerts (AWS Budgets), (3) Right-sizing: match instance sizes to actual usage, (4) Reserved Instances/Savings Plans for predictable workloads, (5) Spot instances for fault-tolerant workloads, (6) Cleanup: identify and terminate unused resources (idle instances, unattached volumes), (7) Storage tiering: lifecycle policies for infrequent data, (8) Regular cost reviews with stakeholders.", category: "Cost", difficulty: "EASY" as const, tags: ["cost-management", "optimization", "cloud"] },
  { questionText: "What is a NAT Gateway?", idealAnswer: "A NAT (Network Address Translation) Gateway allows instances in private subnets to access the internet (for updates, API calls) without being directly accessible from the internet. It translates private IPs to a public IP. Placed in a public subnet, referenced by private subnet route tables. AWS NAT Gateway is managed and highly available within an AZ. Alternative: NAT instance (EC2, cheaper but less reliable). Cost: hourly charge + data processing fee.", category: "Networking", difficulty: "EASY" as const, tags: ["nat-gateway", "networking", "vpc"] },
  { questionText: "What is ElastiCache and when would you use it?", idealAnswer: "ElastiCache is AWS's managed in-memory caching service supporting Redis and Memcached. Use cases: session storage, database query caching, real-time analytics, leaderboards. Redis features: persistence, pub/sub, sorted sets, clustering. Memcached: simpler, multi-threaded, no persistence. Benefits over self-managed: automated failover, patching, backups, scaling. Place between application and database to reduce DB load and improve response times. Typical latency: sub-millisecond.", category: "Databases", difficulty: "EASY" as const, tags: ["elasticache", "redis", "caching"] },
  { questionText: "What is CloudFormation?", idealAnswer: "CloudFormation is AWS's IaC service using YAML/JSON templates to provision resources. Define a stack of resources, CloudFormation creates them in the correct order, handling dependencies. Features: change sets (preview changes), rollback on failure, drift detection, nested stacks. Compared to Terraform: AWS-only, tighter AWS integration, no state file management (AWS manages state). Use for AWS-only projects. Use Terraform for multi-cloud or if you prefer HCL syntax.", category: "IaC", difficulty: "EASY" as const, tags: ["cloudformation", "iac", "aws"] },
  { questionText: "What is a subnet in cloud networking?", idealAnswer: "A subnet is a range of IP addresses within a VPC, tied to a specific Availability Zone. Public subnets have a route to the internet gateway — for load balancers, bastion hosts. Private subnets have no direct internet route — for application servers, databases. Route tables control traffic flow. Best practice: multi-AZ deployment with public and private subnets in each AZ. CIDR block planning: ensure enough IP addresses for growth.", category: "Networking", difficulty: "EASY" as const, tags: ["subnet", "vpc", "networking"] },
  { questionText: "What is AWS Lambda and how does it work?", idealAnswer: "Lambda runs code in response to events without managing servers. Triggers: API Gateway (HTTP), S3 (file upload), SQS (messages), CloudWatch Events (schedule), DynamoDB Streams. Runtime: Node.js, Python, Java, Go, etc. Limits: 15-minute execution, 10GB memory, 250MB deployment package. Pricing: per request + duration (GB-seconds). Cold starts: first invocation is slower (keep functions warm or use provisioned concurrency). Best for: event-driven processing, APIs, scheduled tasks.", category: "Compute", difficulty: "EASY" as const, tags: ["lambda", "serverless", "aws"] },
  { questionText: "What is encryption at rest and in transit?", idealAnswer: "Encryption at rest protects stored data — even if storage is compromised, data is unreadable. AWS: S3 server-side encryption (SSE-S3, SSE-KMS), EBS encryption, RDS encryption. Encryption in transit protects data moving between systems — TLS/HTTPS. Both are essential for compliance (GDPR, HIPAA, SOC 2). AWS KMS (Key Management Service) manages encryption keys. Best practice: encrypt everything by default, use customer-managed keys for sensitive data, rotate keys regularly.", category: "Security", difficulty: "EASY" as const, tags: ["encryption", "kms", "security"] },
  { questionText: "What is a bastion host?", idealAnswer: "A bastion host (jump box) is a hardened server in a public subnet that provides secure SSH access to instances in private subnets. You SSH to the bastion, then SSH from there to private instances. Security: restrict bastion's security group to specific IPs, use key-based auth, audit all access. Modern alternatives: AWS Systems Manager Session Manager (no SSH needed, no bastion, IAM-based access, session logging), AWS EC2 Instance Connect.", category: "Security", difficulty: "EASY" as const, tags: ["bastion", "security", "ssh"] },
  { questionText: "What is the difference between horizontal and vertical scaling in the cloud?", idealAnswer: "Vertical scaling (scale up): increase instance size (t3.micro → t3.xlarge) — requires downtime, has upper limits. Horizontal scaling (scale out): add more instances behind a load balancer — no downtime, theoretically unlimited, requires stateless applications. Cloud makes horizontal scaling easy with auto-scaling groups. Databases: vertical scaling is easier (resize RDS), horizontal requires read replicas or sharding. Always design for horizontal scaling where possible.", category: "Scaling", difficulty: "EASY" as const, tags: ["scaling", "horizontal", "vertical"] },
  { questionText: "What is AWS CloudTrail?", idealAnswer: "CloudTrail logs all API calls made in your AWS account — who did what, when, from where. Records: management events (create/delete resources), data events (S3 object access), insights events (unusual activity). Use for: security auditing, compliance, troubleshooting, change tracking. Deliver logs to S3, analyze with Athena. Enable in all regions. Essential for: incident investigation, compliance (SOC 2, HIPAA), monitoring IAM activity. Set alerts for suspicious actions (root login, security group changes).", category: "Security", difficulty: "EASY" as const, tags: ["cloudtrail", "auditing", "security"] },
  // ===== MEDIUM (40 questions) =====
  { questionText: "How do you design a highly available architecture on AWS?", idealAnswer: "Architecture: (1) Multi-AZ: deploy across at least 2 AZs, (2) Load balancer: ALB distributes traffic across AZs, (3) Auto-scaling: replace failed instances, handle load spikes, (4) Database: RDS Multi-AZ (synchronous standby), read replicas for read-heavy, (5) Caching: ElastiCache with replicas, (6) Storage: S3 for durability, EBS with snapshots, (7) Stateless application servers (sessions in Redis), (8) Health checks at every layer. Target: 99.99% availability. DNS: Route 53 health checks for multi-region failover. Avoid single points of failure.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["high-availability", "multi-az", "architecture"] },
  { questionText: "Explain AWS networking: VPC, subnets, route tables, and gateways.", idealAnswer: "VPC: isolated network with CIDR range (10.0.0.0/16). Subnets: subdivide VPC into AZ-specific ranges. Public subnet: route table has 0.0.0.0/0 → Internet Gateway. Private subnet: 0.0.0.0/0 → NAT Gateway. Internet Gateway: enables public internet access. NAT Gateway: outbound-only internet for private subnets. VPC Peering: connect VPCs. Transit Gateway: hub for multiple VPCs. VPC Endpoints: private access to AWS services without internet. Best practice: public subnets for load balancers only, everything else in private subnets.", category: "Networking", difficulty: "MEDIUM" as const, tags: ["vpc", "networking", "aws"] },
  { questionText: "How do you implement least privilege access in AWS IAM?", idealAnswer: "Practices: (1) Start with zero permissions, add as needed, (2) Use IAM policies with specific actions and resources (not *), (3) Condition keys: restrict by IP, MFA, time, (4) Use IAM roles for services (not access keys), (5) Federated access (SSO) instead of IAM users for humans, (6) Permission boundaries: limit maximum permissions delegated roles can have, (7) Service control policies (SCPs) for organization-wide guardrails, (8) Regular access reviews with IAM Access Analyzer, (9) Remove unused credentials (AWS Config rules). Use: IAM Access Analyzer to identify overly permissive policies.", category: "Security", difficulty: "MEDIUM" as const, tags: ["iam", "least-privilege", "security"] },
  { questionText: "What is AWS Well-Architected Framework?", idealAnswer: "AWS Well-Architected defines best practices across six pillars: (1) Operational Excellence: automate changes, anticipate failure, (2) Security: protect data, manage access, detect threats, (3) Reliability: recover from failures, scale dynamically, (4) Performance Efficiency: use resources efficiently, experiment easily, (5) Cost Optimization: eliminate waste, analyze spending, (6) Sustainability: minimize environmental impact. Use the Well-Architected Tool to review workloads against these pillars. Conduct reviews before production launch and periodically.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["well-architected", "best-practices", "aws"] },
  { questionText: "How do you implement a multi-account AWS strategy?", idealAnswer: "Using AWS Organizations: (1) Management account: billing, organizational policies only, (2) Security account: CloudTrail, GuardDuty, Security Hub aggregation, (3) Networking account: Transit Gateway, shared VPCs, (4) Development/Staging/Production accounts: workload isolation, (5) Sandbox accounts: experimentation. Benefits: blast radius limitation, billing isolation, separate IAM boundaries. Use: SCPs for guardrails, AWS SSO for access, CloudFormation StackSets for cross-account deployment. Control Tower automates setup. Landing Zone provides the initial structure.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["multi-account", "organizations", "aws"] },
  { questionText: "Explain serverless architecture patterns on AWS.", idealAnswer: "Patterns: (1) API: API Gateway → Lambda → DynamoDB (REST/GraphQL endpoints), (2) Event processing: S3 upload → Lambda → process → store result, (3) Async: SQS → Lambda (decoupled processing with retry), (4) Scheduled: EventBridge rule → Lambda (cron jobs), (5) Streaming: Kinesis → Lambda (real-time data processing), (6) Step Functions: orchestrate multi-step workflows with error handling. Benefits: zero infrastructure management, pay-per-use, auto-scaling. Challenges: cold starts, debugging distributed flows, vendor lock-in, testing locally.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["serverless", "lambda", "architecture"] },
  { questionText: "How do you manage Terraform state in a team environment?", idealAnswer: "Remote state: store terraform.tfstate in S3 with DynamoDB lock table. Configuration: `backend \"s3\"` with bucket, key, region, dynamodb_table. Benefits: team collaboration, state locking prevents concurrent modifications, encryption at rest. Best practices: separate state files per environment (dev/staging/prod), use workspaces cautiously, never commit state to Git (contains secrets), enable versioning on S3 bucket for state recovery. Remote state data sources enable cross-project references.", category: "IaC", difficulty: "MEDIUM" as const, tags: ["terraform", "state", "iac"] },
  { questionText: "What is AWS EKS and how do you set it up?", idealAnswer: "EKS is AWS's managed Kubernetes service. Setup: (1) Create EKS cluster (Terraform or eksctl): control plane is managed by AWS, (2) Node groups: managed (AWS manages EC2), self-managed (you manage), or Fargate (serverless), (3) Networking: VPC with public/private subnets, ALB Ingress Controller, (4) IAM: IRSA (IAM Roles for Service Accounts) for pod-level permissions, (5) Add-ons: CoreDNS, kube-proxy, VPC CNI, (6) Observability: CloudWatch Container Insights or Prometheus. Cost: $0.10/hr for control plane + node costs. Use eksctl or Terraform modules for repeatable setup.", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["eks", "kubernetes", "aws"] },
  { questionText: "How do you implement disaster recovery across AWS regions?", idealAnswer: "Strategies by RTO/RPO: (1) Backup & Restore (RPO hours, RTO hours): cross-region backups, rebuild from IaC, (2) Pilot Light (RPO minutes, RTO tens of minutes): core infrastructure running in DR region (database replica), scale up on failover, (3) Warm Standby (RPO seconds, RTO minutes): scaled-down copy running in DR, scale to full on failover, (4) Active-Active (RPO ~0, RTO ~0): both regions serve traffic via Route 53. Key: cross-region RDS read replica, S3 cross-region replication, IaC for both regions, tested runbooks, automated failover via Route 53 health checks.", category: "Reliability", difficulty: "MEDIUM" as const, tags: ["disaster-recovery", "multi-region", "aws"] },
  { questionText: "What is AWS CloudWatch and how do you set up effective monitoring?", idealAnswer: "CloudWatch collects metrics, logs, and events. Setup: (1) Metrics: EC2 (CPU, network), RDS (connections, IOPS), ALB (request count, latency), custom metrics via SDK, (2) Alarms: threshold-based (CPU > 80% for 5 min), anomaly detection, composite alarms, (3) Dashboards: service-level views with key metrics, (4) Logs: collect from Lambda, ECS, EC2 (CloudWatch Agent), set metric filters for error patterns, (5) Alerts: SNS → email/Slack/PagerDuty. Best practices: alarm on symptoms not causes, use metric math for derived metrics, set up log retention policies to control costs.", category: "Monitoring", difficulty: "MEDIUM" as const, tags: ["cloudwatch", "monitoring", "aws"] },
  { questionText: "How do you implement a CI/CD pipeline for cloud infrastructure?", idealAnswer: "Pipeline: (1) Git push triggers pipeline (GitHub Actions, CodePipeline), (2) Terraform fmt + validate (syntax check), (3) tfsec/checkov (security scanning), (4) Terraform plan (preview changes, comment on PR), (5) Manual approval for production, (6) Terraform apply with state locking, (7) Post-apply verification (health checks, smoke tests). Safeguards: separate pipelines per environment, destroy protection on critical resources, policy as code (Sentinel/OPA), cost estimation (Infracost). Store plan output as artifact for apply step.", category: "CI/CD", difficulty: "MEDIUM" as const, tags: ["ci-cd", "terraform", "infrastructure"] },
  { questionText: "What are the different database options on AWS and when to use each?", idealAnswer: "Relational: RDS (PostgreSQL, MySQL — managed, Multi-AZ), Aurora (MySQL/PostgreSQL compatible, 5x throughput, serverless option). NoSQL: DynamoDB (key-value, single-digit ms latency, auto-scaling), DocumentDB (MongoDB compatible). In-memory: ElastiCache (Redis/Memcached). Graph: Neptune. Time-series: Timestream. Search: OpenSearch. Choose: RDS for structured data with complex queries, DynamoDB for high-throughput key-value access, Aurora for high-performance relational, ElastiCache for caching.", category: "Databases", difficulty: "MEDIUM" as const, tags: ["databases", "rds", "dynamodb"] },
  { questionText: "How do you secure data in AWS?", idealAnswer: "Encryption: (1) At rest: S3 SSE-KMS, EBS encryption, RDS encryption (enable at creation), (2) In transit: TLS for all connections, VPC endpoints for AWS service access, (3) Key management: KMS for key creation, rotation, access policies, (4) Data classification: tag data by sensitivity, (5) Access control: S3 bucket policies + IAM, block public access, (6) Logging: CloudTrail for API access, S3 access logs, (7) Compliance: AWS Config rules to enforce encryption, Macie for PII detection, (8) VPC: private subnets for databases, security groups restricting access to known sources.", category: "Security", difficulty: "MEDIUM" as const, tags: ["security", "encryption", "data-protection"] },
  { questionText: "Explain AWS networking with Transit Gateway and VPC Peering.", idealAnswer: "VPC Peering: direct connection between two VPCs, non-transitive (A-B peered, B-C peered, doesn't mean A-C can communicate). Simple for few VPCs. Transit Gateway: hub-and-spoke model connecting multiple VPCs and on-premises networks. All VPCs route through the TGW — transitive routing, centralized network management. Use peering for: simple 2-VPC connections. Use Transit Gateway for: many VPCs, hybrid connectivity, centralized routing, network segmentation. TGW supports route tables for network isolation between environments.", category: "Networking", difficulty: "MEDIUM" as const, tags: ["transit-gateway", "vpc-peering", "networking"] },
  { questionText: "How do you implement cost optimization for AWS workloads?", idealAnswer: "Strategies: (1) Right-sizing: use Compute Optimizer recommendations, (2) Savings Plans: commit to consistent usage (up to 72% savings), (3) Spot Instances: for fault-tolerant workloads (up to 90% off), (4) Auto-scaling: scale down during off-hours, (5) Storage: S3 lifecycle policies (Standard → IA → Glacier), delete unused EBS volumes, (6) Reserved capacity: RDS Reserved Instances, ElastiCache Reserved Nodes, (7) Architecture: use serverless where appropriate (pay per request), (8) Monitoring: Cost Explorer, Budgets with alerts, Trusted Advisor. Implement tagging policy for cost allocation. Regular monthly cost reviews.", category: "Cost", difficulty: "MEDIUM" as const, tags: ["cost-optimization", "savings-plans", "aws"] },
  { questionText: "What is AWS Systems Manager and how does it help manage infrastructure?", idealAnswer: "Systems Manager is a suite of operations tools: (1) Session Manager: secure shell access without SSH/bastion, audit logged, (2) Parameter Store: hierarchical configuration and secrets storage, (3) Patch Manager: automated OS patching across fleets, (4) Run Command: execute commands on multiple instances, (5) Automation: runbooks for operational tasks, (6) Inventory: collect software/configuration from instances, (7) State Manager: enforce desired configuration. Benefits: no SSH keys to manage, IAM-based access, full audit trail, centralized management. Use Parameter Store for non-sensitive config, Secrets Manager for rotating secrets.", category: "Operations", difficulty: "MEDIUM" as const, tags: ["systems-manager", "operations", "aws"] },
  { questionText: "How do you implement logging and monitoring for a serverless application?", idealAnswer: "Logging: Lambda automatically sends logs to CloudWatch Logs. Add structured logging (JSON) with correlation IDs. Use CloudWatch Logs Insights for querying. API Gateway: enable access logging and execution logging. Monitoring: (1) CloudWatch Metrics: Lambda invocations, errors, duration, throttles, concurrent executions, (2) Custom metrics for business logic, (3) X-Ray for distributed tracing across Lambda → DynamoDB → SQS, (4) Alarms on: error rate > threshold, duration approaching timeout, throttle events. Dashboard: function-level metrics, API latency, error breakdown by function.", category: "Monitoring", difficulty: "MEDIUM" as const, tags: ["serverless", "monitoring", "cloudwatch"] },
  { questionText: "What is DynamoDB and when should you use it?", idealAnswer: "DynamoDB is a fully managed NoSQL key-value/document database. Features: single-digit millisecond latency, auto-scaling, global tables (multi-region), streams (change data capture), TTL. Design: partition key for distribution, sort key for querying within partition, GSIs for alternative access patterns. Use when: known access patterns, high throughput needed, simple queries (key lookups), automatic scaling required. Don't use for: complex queries/joins, ad-hoc analytics, small workloads (minimum cost). Design the schema around access patterns, not data relationships.", category: "Databases", difficulty: "MEDIUM" as const, tags: ["dynamodb", "nosql", "aws"] },
  { questionText: "How do you implement network security in AWS?", idealAnswer: "Layers: (1) VPC: isolate environments in separate VPCs, (2) Subnets: private subnets for databases/apps, public only for load balancers, (3) Security Groups: instance-level, allow only needed ports from specific sources, (4) NACLs: subnet-level deny rules for additional defense, (5) VPC Flow Logs: monitor traffic for anomalies, (6) WAF: protect against Layer 7 attacks on ALB/CloudFront, (7) GuardDuty: threat detection from VPC logs, DNS, CloudTrail, (8) VPC Endpoints: access AWS services without internet exposure, (9) PrivateLink: expose services privately to other VPCs. Defense in depth: multiple layers, each catching different threats.", category: "Security", difficulty: "MEDIUM" as const, tags: ["network-security", "vpc", "aws"] },
  { questionText: "How do you manage multiple environments (dev/staging/prod) in AWS?", idealAnswer: "Approaches: (1) Separate AWS accounts per environment (recommended): strongest isolation, independent billing, IAM boundaries, (2) Same account, different VPCs: simpler but weaker isolation, (3) Infrastructure as Code: Terraform workspaces or separate state files per environment, (4) Parameter stores: environment-specific configuration, (5) CI/CD: automated promotion (dev → staging → prod) with gates, (6) Naming conventions: resource names include environment prefix. Best practice: use AWS Organizations with separate accounts, SSO for access, consistent Terraform modules across environments with different variable values.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["environments", "multi-account", "aws"] },
  { questionText: "What is AWS Step Functions and when should you use it?", idealAnswer: "Step Functions orchestrates multi-step serverless workflows using state machines. States: Task (Lambda, ECS, API calls), Choice (branching), Parallel (concurrent execution), Wait (delay), Map (iterate over items). Use for: order processing pipelines, data ETL workflows, ML training pipelines, approval workflows. Benefits: visual workflow, built-in error handling and retry, long-running workflows (up to 1 year), audit trail. Express Workflows for high-volume, short-duration. Standard for long-running, exactly-once. Better than chaining Lambdas directly for complex flows.", category: "Compute", difficulty: "MEDIUM" as const, tags: ["step-functions", "orchestration", "serverless"] },
  { questionText: "How do you implement a microservices architecture on AWS?", idealAnswer: "Architecture: (1) Compute: ECS/EKS for containers or Lambda for serverless, (2) Networking: ALB for HTTP routing, API Gateway for managed API layer, (3) Communication: synchronous (HTTP/gRPC) for queries, SQS/SNS/EventBridge for async events, (4) Database: database per service (RDS, DynamoDB), (5) Service discovery: Cloud Map or Kubernetes DNS, (6) Observability: X-Ray for tracing, CloudWatch for metrics/logs, (7) Security: IAM roles per service, mutual TLS with App Mesh, (8) CI/CD: independent pipelines per service. API Gateway handles: authentication, rate limiting, request transformation.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["microservices", "ecs", "architecture"] },
  { questionText: "What is AWS EventBridge and how does it enable event-driven architectures?", idealAnswer: "EventBridge is a serverless event bus that routes events between AWS services, SaaS providers, and custom applications. Features: schema registry (auto-discover event shapes), rules with filtering patterns, multiple targets (Lambda, SQS, Step Functions), event replay, archive. Use for: decoupling services (order-placed → notification + inventory + analytics), cross-account events, SaaS integration (Stripe events → Lambda). Compared to SNS: richer filtering, content-based routing, schema management. Event-driven architecture reduces coupling and enables independent scaling.", category: "Messaging", difficulty: "MEDIUM" as const, tags: ["eventbridge", "event-driven", "aws"] },
  { questionText: "How do you implement a data lake on AWS?", idealAnswer: "Architecture: (1) Ingest: Kinesis Firehose (streaming), Glue (batch ETL), DMS (database migration), S3 Transfer Acceleration (large files), (2) Storage: S3 organized by zones — raw (landing), cleaned, curated (analytics-ready), (3) Catalog: Glue Data Catalog with crawlers for schema discovery, (4) Processing: Glue ETL (Spark), Athena (SQL on S3), EMR (Spark/Hadoop), (5) Analytics: Athena for ad-hoc, Redshift for data warehouse, QuickSight for BI, (6) Security: Lake Formation for access control, encryption, column-level permissions. Use Parquet/ORC format for analytics. Partition by date/key for query performance.", category: "Data", difficulty: "MEDIUM" as const, tags: ["data-lake", "s3", "analytics"] },
  { questionText: "What is AWS Fargate and when should you use it over EC2?", idealAnswer: "Fargate is serverless container compute — you define CPU/memory per task, AWS manages the underlying infrastructure. No EC2 instances to manage, patch, or scale. Use Fargate when: you want no infrastructure management, workloads are variable, you're running many small services, security requires per-task isolation. Use EC2 when: you need GPU, specific instance types, persistent local storage, or cost optimization with reserved instances. Fargate pricing is per vCPU/memory per second — more expensive per unit but saves ops time.", category: "Compute", difficulty: "MEDIUM" as const, tags: ["fargate", "ecs", "serverless"] },
  // ===== HARD (30 questions) =====
  { questionText: "Design a multi-region active-active architecture on AWS.", idealAnswer: "Architecture: (1) Route 53 latency-based routing to nearest region, (2) Per-region: ALB → ECS/EKS auto-scaling → Aurora Global Database, (3) Database: Aurora Global with write-forwarding (reads local, writes to primary, replicated in <1s), or DynamoDB Global Tables (multi-master), (4) Caching: ElastiCache per region with application-level invalidation, (5) S3: cross-region replication for assets, (6) Session management: DynamoDB or ElastiCache Global Datastore, (7) Event synchronization: EventBridge cross-region rules, (8) CDN: CloudFront with regional origins. Challenges: data consistency (eventual consistency acceptable?), conflict resolution, cost (double infrastructure), testing failover.", category: "Architecture", difficulty: "HARD" as const, tags: ["multi-region", "active-active", "architecture"] },
  { questionText: "How do you implement a zero-trust network architecture in AWS?", idealAnswer: "Implementation: (1) Identity-centric: IAM everywhere, IRSA for Kubernetes pods, no network-based trust, (2) Micro-segmentation: security groups per service, VPC endpoints for AWS API access, PrivateLink for cross-account, (3) Encryption: TLS for all communication, VPN/Direct Connect for hybrid, mTLS via App Mesh, (4) Verification: every request authenticated and authorized (no implicit trust from VPC location), (5) Monitoring: VPC Flow Logs, GuardDuty, CloudTrail for complete visibility, (6) Access: SSO with MFA, Session Manager instead of SSH, short-lived credentials via STS, (7) Data: encryption at rest with CMKs, bucket policies deny public access. No trusted network zones — verify everything.", category: "Security", difficulty: "HARD" as const, tags: ["zero-trust", "security", "networking"] },
  { questionText: "Design a cost-optimized architecture for a variable-traffic web application.", idealAnswer: "Architecture: (1) CloudFront CDN for static assets (80%+ of requests served from edge), (2) Auto-scaling group with mixed instances: on-demand base (minimum capacity) + spot instances (variable capacity, 70-90% cheaper), (3) Savings Plans for baseline compute, (4) Aurora Serverless v2 for database (auto-scales between min/max, pay per ACU), (5) ElastiCache Serverless for caching, (6) Lambda for async processing (email, image resize), (7) S3 Intelligent-Tiering for storage, (8) Scheduled scaling: pre-scale for known peaks, scale down overnight. Monitoring: Kubecost or AWS Cost Explorer with anomaly detection. Target: 40-60% cost reduction vs all on-demand.", category: "Architecture", difficulty: "HARD" as const, tags: ["cost-optimization", "auto-scaling", "architecture"] },
  { questionText: "How do you design a compliant cloud architecture for healthcare (HIPAA)?", idealAnswer: "Requirements: (1) BAA (Business Associate Agreement) with AWS, use only HIPAA-eligible services, (2) Encryption: at rest (KMS with CMKs, mandatory for all PHI storage) and in transit (TLS 1.2+), (3) Access control: IAM least privilege, MFA required, no shared accounts, (4) Audit: CloudTrail (all regions, enabled, no deletion), CloudWatch Logs with retention, (5) Network: private subnets for PHI, no public access, VPC endpoints, (6) Logging: access logs for all PHI data stores, (7) Backup: automated with encryption, tested restores, (8) Incident response: documented plan, GuardDuty enabled. Separate PHI workloads in dedicated accounts. Regular compliance audits with AWS Config rules.", category: "Compliance", difficulty: "HARD" as const, tags: ["hipaa", "compliance", "healthcare"] },
  { questionText: "How would you migrate a large on-premises database to AWS?", idealAnswer: "Strategy by size and downtime tolerance: (1) Small (<1TB), downtime OK: pg_dump/restore or DMS full load, (2) Medium, minimal downtime: DMS full load + CDC (change data capture) for ongoing replication, cutover when caught up, (3) Large (>10TB): Snowball Edge for initial data, then DMS CDC for delta, (4) Schema conversion: SCT (Schema Conversion Tool) for heterogeneous migrations (Oracle→PostgreSQL). Steps: assess (SCT assessment), migrate schema, migrate data, validate (row counts, checksums), cutover (update DNS, stop writes to source), monitor. Plan for: application testing, performance benchmarking, rollback procedure. Timeline: weeks to months depending on complexity.", category: "Migration", difficulty: "HARD" as const, tags: ["migration", "dms", "databases"] },
  { questionText: "Design a serverless data processing pipeline for real-time analytics.", idealAnswer: "Architecture: (1) Ingest: API Gateway → Kinesis Data Streams (real-time event ingestion), (2) Process: Lambda consumers for enrichment, transformation, validation, (3) Real-time: Kinesis Data Analytics (SQL on streaming data) for aggregations, anomaly detection, (4) Store: Kinesis Firehose → S3 (partitioned by date/hour, Parquet format), DynamoDB for real-time counters, (5) Batch: Glue ETL for daily aggregations, (6) Query: Athena for ad-hoc, Redshift Spectrum for complex analytics, (7) Visualize: QuickSight dashboards. Handle: late events (watermarking), deduplication (idempotent processing), backpressure (Kinesis scaling). Cost: pay per Kinesis shard, Lambda invocation, Athena query.", category: "Architecture", difficulty: "HARD" as const, tags: ["serverless", "analytics", "streaming"] },
  { questionText: "How do you implement a comprehensive AWS security posture management?", idealAnswer: "Implementation: (1) Preventive: SCPs (block dangerous actions), IAM policies (least privilege), S3 Block Public Access, (2) Detective: GuardDuty (threat detection), Security Hub (aggregate findings), Config (compliance rules), Inspector (vulnerability scanning), Macie (PII detection), (3) Responsive: EventBridge rules → Lambda for auto-remediation (revoke public S3, disable compromised keys), (4) Monitoring: CloudTrail (API audit), VPC Flow Logs (network), CloudWatch Alarms, (5) Compliance: Config rules for CIS benchmarks, automated compliance reports, (6) Regular: access reviews, penetration testing, security training. Aggregate in Security Hub, prioritize by severity, track remediation SLAs.", category: "Security", difficulty: "HARD" as const, tags: ["security-posture", "guardduty", "security-hub"] },
  { questionText: "Design a hybrid cloud architecture connecting on-premises to AWS.", idealAnswer: "Connectivity: (1) AWS Direct Connect: dedicated network connection (1-100 Gbps), consistent latency, (2) Site-to-Site VPN: encrypted over internet, cheaper, redundant with multiple tunnels, (3) Transit Gateway: hub for multiple VPCs and VPN/DX connections. Architecture: (4) DNS: Route 53 Resolver for hybrid DNS resolution, (5) Directory: AWS Directory Service connected to on-prem AD, (6) Storage: Storage Gateway for hybrid file/block access, (7) Data: DMS for database replication to cloud, (8) Identity: SSO federation with on-prem IdP. Patterns: extend (same apps across environments), migrate (gradual move to cloud), burst (overflow to cloud during peaks). Network design: consistent IP addressing, avoid overlapping CIDRs.", category: "Architecture", difficulty: "HARD" as const, tags: ["hybrid-cloud", "direct-connect", "architecture"] },
  { questionText: "How do you implement a landing zone for a new AWS organization?", idealAnswer: "Components: (1) AWS Control Tower: automates multi-account setup with guardrails, (2) Account structure: management, security, log archive, shared services, workload accounts (dev/staging/prod), (3) Networking: Transit Gateway in networking account, shared VPCs, centralized egress, (4) Security: CloudTrail organization trail, GuardDuty delegated admin, Security Hub aggregation, (5) Identity: AWS SSO with IdP integration, permission sets per role, (6) Guardrails: preventive (SCPs), detective (Config rules), (7) Baseline: Terraform/CloudFormation for standard account setup (VPC, IAM roles, logging). Use Account Factory for standardized account provisioning. Document standards for teams.", category: "Architecture", difficulty: "HARD" as const, tags: ["landing-zone", "control-tower", "organizations"] },
  { questionText: "Design an architecture for handling 100K requests per second.", idealAnswer: "Architecture: (1) CloudFront: cache static + cacheable dynamic content at edge, handle 100K+ req/s easily, (2) Route 53: latency-based routing to nearest region, (3) ALB: auto-scales, handles millions of requests, (4) Compute: ECS/EKS on c5/c6g instances with HPA, minimum 20-30 instances, auto-scale based on request count, (5) Cache: ElastiCache Redis cluster (sub-ms reads, offload 80% of DB queries), (6) Database: Aurora with read replicas (read-heavy) or DynamoDB (predictable performance at any scale), (7) Async: SQS for non-critical processing, (8) Static assets: S3 + CloudFront. Key: cache aggressively, use connection pooling, optimize queries, minimize network hops. Load test before launch.", category: "Architecture", difficulty: "HARD" as const, tags: ["high-traffic", "scaling", "architecture"] },
  { questionText: "How do you implement a secure container deployment pipeline on AWS?", idealAnswer: "Pipeline: (1) Source: CodeCommit/GitHub with branch protection, signed commits, (2) Build: CodeBuild with VPC access, no internet (use VPC endpoints), (3) Scan: ECR native scanning + Trivy/Snyk for vulnerability detection, block on critical CVEs, (4) Sign: Cosign image signing, store signatures in ECR, (5) Registry: ECR with lifecycle policies, image immutability, (6) Deploy: Kubernetes admission controller verifies image signature and registry source, (7) Runtime: Falco for behavioral monitoring, read-only filesystem, non-root, (8) Secrets: external-secrets-operator pulling from Secrets Manager. SBOM generation and storage for compliance. Block deployment if any security gate fails.", category: "Security", difficulty: "HARD" as const, tags: ["container-security", "pipeline", "devsecops"] },
  { questionText: "How would you design a global content delivery platform on AWS?", idealAnswer: "Architecture: (1) CloudFront: 400+ edge locations, origin groups for failover, Lambda@Edge for request transformation, (2) Origins: S3 for static (versioned, replicated), ALB for dynamic (multi-region), (3) Media: MediaConvert for transcoding, MediaPackage for video streaming, S3 + CloudFront for delivery, (4) Acceleration: Global Accelerator for non-HTTP traffic, (5) DNS: Route 53 with geolocation routing, (6) Caching strategy: aggressive TTLs for static, short/no cache for personalized, cache keys based on relevant headers, (7) Security: WAF on CloudFront, signed URLs/cookies for premium content, OAC for S3 access, (8) Monitoring: CloudFront real-time logs → Kinesis → analytics. Optimize: cache hit ratio > 95%, invalidation strategy, custom error pages.", category: "Architecture", difficulty: "HARD" as const, tags: ["cdn", "cloudfront", "global"] },
  { questionText: "How do you implement AWS cost allocation and chargeback?", idealAnswer: "Implementation: (1) Tagging strategy: mandatory tags (team, environment, project, cost-center) enforced by SCP/Config rules, (2) Cost allocation tags: activate in Billing console, (3) AWS Organizations: separate accounts per team/product for natural cost boundaries, (4) Cost Explorer: filter/group by tags, create team-specific reports, (5) CUR (Cost and Usage Report): detailed hourly data to S3, query with Athena, (6) Dashboards: QuickSight/Grafana showing team costs, trends, anomalies, (7) Budgets: per-team budgets with alerts, (8) Shared resources: allocate proportionally (EKS cluster costs by namespace CPU/memory). Monthly cost reviews with team leads. Track unit economics (cost per transaction/user).", category: "Cost", difficulty: "HARD" as const, tags: ["cost-allocation", "chargeback", "finops"] },
  { questionText: "Design a machine learning infrastructure on AWS.", idealAnswer: "Architecture: (1) Data: S3 data lake with Glue catalog, Feature Store (SageMaker), (2) Training: SageMaker training jobs with spot instances (70% cost savings), distributed training for large models, (3) Experiment tracking: SageMaker Experiments or MLflow on EKS, (4) Model registry: SageMaker Model Registry with approval workflow, (5) Serving: SageMaker endpoints (real-time), batch transform (batch), Lambda (lightweight models), (6) Pipeline: SageMaker Pipelines or Step Functions for ML workflows, (7) Monitoring: SageMaker Model Monitor for data/model drift, CloudWatch for endpoint metrics. GPU instances: p4d (training), g5 (inference). Use SageMaker Studio for notebook environment.", category: "Architecture", difficulty: "HARD" as const, tags: ["ml-infrastructure", "sagemaker", "architecture"] },
  { questionText: "How do you implement a multi-tenant SaaS platform on AWS?", idealAnswer: "Isolation models: (1) Silo: separate AWS accounts per tenant — strongest isolation, highest cost, for enterprise/compliance, (2) Bridge: shared compute, separate databases — moderate isolation, (3) Pool: shared everything with tenant_id filtering — lowest cost, highest density. Implementation: (1) Identity: Cognito with tenant context in JWT, (2) Data: RDS with row-level security or DynamoDB with tenant partition key, (3) Compute: EKS with namespace per tenant or shared with tenant middleware, (4) Networking: tenant-specific domains via Route 53, (5) Metering: track usage per tenant for billing (API calls, storage, compute), (6) Onboarding: automated tenant provisioning pipeline. Noisy neighbor protection: resource quotas, rate limiting per tenant.", category: "Architecture", difficulty: "HARD" as const, tags: ["multi-tenant", "saas", "architecture"] },
  { questionText: "How would you design an event-driven architecture on AWS?", idealAnswer: "Architecture: (1) Event bus: EventBridge for routing events between services, (2) Event sources: application events, AWS service events, SaaS webhooks, (3) Event schema: Schema Registry for discovery and validation, (4) Processing: Lambda for stateless, Step Functions for workflows, ECS for long-running, (5) Streaming: Kinesis for high-throughput ordered events, (6) Storage: S3 event archive for replay, DynamoDB for event store, (7) Patterns: fan-out (one event → multiple consumers), event sourcing (events as source of truth), saga orchestration. Best practices: idempotent consumers, dead letter queues, event versioning, retry policies. Challenge: eventual consistency — design for it from the start.", category: "Architecture", difficulty: "HARD" as const, tags: ["event-driven", "eventbridge", "architecture"] },
];
