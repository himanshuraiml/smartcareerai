export const devopsEngineerQuestions = [
  // ===== EASY (30 questions) =====
  { questionText: "What is DevOps and what problems does it solve?", idealAnswer: "DevOps is a set of practices combining software development (Dev) and IT operations (Ops) to shorten the development lifecycle and deliver high-quality software continuously. It solves: slow release cycles, dev-ops silos, manual error-prone deployments, poor incident response. Key practices: CI/CD, infrastructure as code, monitoring, collaboration. Culture matters as much as tools.", category: "Fundamentals", difficulty: "EASY" as const, tags: ["devops", "culture", "fundamentals"] },
  { questionText: "What is CI/CD and why is it important?", idealAnswer: "CI (Continuous Integration) automatically builds and tests code on every commit. CD (Continuous Delivery) automatically deploys passing builds to staging; Continuous Deployment goes to production. Benefits: catch bugs early, reduce integration conflicts, faster releases, consistent builds, reduced manual errors. Pipeline: code push → lint → test → build → deploy. Tools: GitHub Actions, GitLab CI, Jenkins, CircleCI.", category: "CI/CD", difficulty: "EASY" as const, tags: ["ci-cd", "automation", "pipeline"] },
  { questionText: "What is Docker and how do containers differ from virtual machines?", idealAnswer: "Docker packages applications with dependencies into containers. Containers share the host OS kernel — lightweight, fast to start (seconds), and portable. VMs include a full guest OS — heavier, slower to start (minutes), but stronger isolation. Containers are better for microservices and CI/CD; VMs for running different OS or stronger security isolation. Docker uses images (immutable blueprints) and containers (running instances).", category: "Containers", difficulty: "EASY" as const, tags: ["docker", "containers", "vms"] },
  { questionText: "What is a Dockerfile and what are its key instructions?", idealAnswer: "A Dockerfile defines how to build a Docker image. Key instructions: FROM (base image), COPY/ADD (add files), RUN (execute commands during build), WORKDIR (set directory), ENV (set variables), EXPOSE (document ports), CMD/ENTRYPOINT (startup command). Best practices: use specific base image tags, multi-stage builds to reduce size, minimize layers, don't run as root, use .dockerignore.", category: "Containers", difficulty: "EASY" as const, tags: ["docker", "dockerfile", "images"] },
  { questionText: "What is version control and why is Git essential for DevOps?", idealAnswer: "Version control tracks file changes over time. Git is a distributed VCS enabling collaboration, branching, and history. Essential for DevOps because: CI/CD triggers on Git events, infrastructure as code is stored in Git, configuration changes are tracked, rollbacks are possible. Branching strategies: GitHub Flow (simple), GitFlow (complex). Git enables code review via pull requests and audit trails.", category: "Git", difficulty: "EASY" as const, tags: ["git", "version-control", "collaboration"] },
  { questionText: "What is Infrastructure as Code (IaC)?", idealAnswer: "IaC manages infrastructure through code files instead of manual processes. Benefits: reproducible environments, version-controlled changes, automated provisioning, documentation as code, easy disaster recovery. Tools: Terraform (multi-cloud, declarative), AWS CloudFormation, Pulumi (general-purpose languages), Ansible (configuration management). Store IaC in Git, review changes via PRs, apply via CI/CD pipelines.", category: "IaC", difficulty: "EASY" as const, tags: ["iac", "terraform", "automation"] },
  { questionText: "What is a load balancer and why is it needed?", idealAnswer: "A load balancer distributes incoming traffic across multiple servers to ensure no single server is overwhelmed. Benefits: high availability (if one server fails, others handle traffic), scalability (add servers as traffic grows), health checking (route away from unhealthy servers). Types: Layer 4 (TCP, faster) and Layer 7 (HTTP, smarter routing). Tools: Nginx, HAProxy, AWS ALB/NLB.", category: "Networking", difficulty: "EASY" as const, tags: ["load-balancer", "networking", "scaling"] },
  { questionText: "What is Linux and why is it important for DevOps?", idealAnswer: "Linux is an open-source operating system that runs the majority of servers, containers, and cloud instances. DevOps engineers need Linux skills for: server administration, troubleshooting, scripting (bash), networking, container runtimes. Key skills: file system navigation, process management, permissions, package management (apt/yum), systemd services, log analysis. Most Docker images and CI runners use Linux.", category: "Linux", difficulty: "EASY" as const, tags: ["linux", "os", "administration"] },
  { questionText: "What is the difference between TCP and UDP?", idealAnswer: "TCP is connection-oriented with guaranteed delivery, ordering, and error checking — used for HTTP, SSH, database connections. UDP is connectionless with no delivery guarantee — faster, lower overhead, used for DNS, streaming, gaming. TCP establishes a 3-way handshake before data transfer. UDP just sends packets. Choose TCP for reliability, UDP for speed when occasional packet loss is acceptable.", category: "Networking", difficulty: "EASY" as const, tags: ["networking", "tcp", "udp"] },
  { questionText: "What is a reverse proxy?", idealAnswer: "A reverse proxy sits in front of backend servers, forwarding client requests. Functions: load balancing, SSL termination, caching static content, request buffering, rate limiting, hiding backend topology. Nginx is the most common reverse proxy. Configuration: map URLs to upstream servers, set timeouts, add headers. In production: Client → Nginx (reverse proxy) → Application server → Database.", category: "Networking", difficulty: "EASY" as const, tags: ["reverse-proxy", "nginx", "networking"] },
  { questionText: "What is DNS and how does it work?", idealAnswer: "DNS (Domain Name System) translates domain names to IP addresses. Process: browser checks cache → OS resolver → recursive DNS server → root nameserver → TLD nameserver → authoritative nameserver → returns IP. Record types: A (IPv4), AAAA (IPv6), CNAME (alias), MX (mail), TXT (verification), NS (nameserver). TTL controls cache duration. DNS is critical for service discovery and traffic routing.", category: "Networking", difficulty: "EASY" as const, tags: ["dns", "networking", "resolution"] },
  { questionText: "What is monitoring and why is it essential?", idealAnswer: "Monitoring observes system health and performance in real-time. Three pillars: metrics (numbers — CPU, memory, request rate), logs (events — errors, access logs), traces (request flows across services). Essential for: detecting outages, capacity planning, performance optimization, alerting on-call teams. Tools: Prometheus (metrics), Grafana (dashboards), ELK (logs), Jaeger (traces). Monitor infrastructure, applications, and business metrics.", category: "Monitoring", difficulty: "EASY" as const, tags: ["monitoring", "observability", "metrics"] },
  { questionText: "What is SSH and how does key-based authentication work?", idealAnswer: "SSH (Secure Shell) provides encrypted remote access to servers. Key-based auth: generate a key pair (ssh-keygen), place public key on the server (~/.ssh/authorized_keys), authenticate with private key. More secure than passwords — no brute force risk, no credential transmission. Best practices: use Ed25519 keys, protect private key with passphrase, disable password auth on servers, use SSH agent for convenience.", category: "Security", difficulty: "EASY" as const, tags: ["ssh", "security", "authentication"] },
  { questionText: "What is a container registry?", idealAnswer: "A container registry stores and distributes Docker images. Push images after building, pull them for deployment. Types: Docker Hub (public default), Amazon ECR, Google GCR, GitHub Container Registry, self-hosted (Harbor). Use tags for versioning (v1.2.3, latest). In CI/CD: build image → tag → push to registry → deploy from registry. Security: scan images for vulnerabilities, use signed images, restrict access.", category: "Containers", difficulty: "EASY" as const, tags: ["container-registry", "docker", "images"] },
  { questionText: "What are environment variables and how are they used in DevOps?", idealAnswer: "Environment variables configure applications without code changes — database URLs, API keys, feature flags, port numbers. Benefits: separate config from code, different values per environment, secrets stay out of version control. Set via: Docker env/env_file, Kubernetes ConfigMaps/Secrets, CI/CD pipeline variables, cloud platform config. Follow the twelve-factor app methodology: store config in the environment.", category: "Configuration", difficulty: "EASY" as const, tags: ["environment-variables", "config", "twelve-factor"] },
  { questionText: "What is YAML and why is it used in DevOps?", idealAnswer: "YAML (YAML Ain't Markup Language) is a human-readable data format used for configuration files. Used in: Docker Compose, Kubernetes manifests, CI/CD pipelines (GitHub Actions, GitLab CI), Ansible playbooks, Terraform (HCL is similar). Features: indentation-based nesting, lists, key-value pairs, comments. Be careful with: indentation (spaces, not tabs), string quoting, boolean interpretation ('yes' = true). YAML is the lingua franca of DevOps configuration.", category: "Tools", difficulty: "EASY" as const, tags: ["yaml", "configuration", "tools"] },
  { questionText: "What is a CI/CD pipeline and what stages does it typically have?", idealAnswer: "A pipeline automates the build-test-deploy workflow. Common stages: (1) Source: trigger on git push/PR, (2) Build: compile code, install dependencies, (3) Test: unit tests, linting, type checking, (4) Security: vulnerability scanning, SAST, (5) Build artifacts: Docker images, (6) Deploy to staging, (7) Integration/E2E tests, (8) Deploy to production, (9) Smoke tests. Each stage must pass before the next. Failed stages halt the pipeline.", category: "CI/CD", difficulty: "EASY" as const, tags: ["ci-cd", "pipeline", "stages"] },
  { questionText: "What is Docker Compose?", idealAnswer: "Docker Compose defines and runs multi-container applications using a YAML file. Specify services, networks, volumes, environment variables, and dependencies. Example: app + database + cache in one file. Commands: `docker-compose up` (start), `docker-compose down` (stop), `docker-compose logs` (view logs). Used for: local development environments, testing, simple deployments. For production at scale, use Kubernetes instead.", category: "Containers", difficulty: "EASY" as const, tags: ["docker-compose", "containers", "orchestration"] },
  { questionText: "What is the difference between horizontal and vertical scaling?", idealAnswer: "Vertical scaling (scale up): add more CPU/RAM to a single server — simpler but has hardware limits. Horizontal scaling (scale out): add more servers behind a load balancer — handles unlimited traffic, provides redundancy, but requires stateless applications. Vertical: good for databases. Horizontal: good for application servers, containers. Cloud auto-scaling is horizontal. Most production systems use both strategies.", category: "Scaling", difficulty: "EASY" as const, tags: ["scaling", "horizontal", "vertical"] },
  { questionText: "What is a firewall and what types exist?", idealAnswer: "A firewall controls network traffic based on rules. Types: network firewall (Layer 3/4 — IP addresses, ports), application firewall (Layer 7 — HTTP requests, WAF), host-based (iptables/ufw on individual servers). Cloud: Security Groups (AWS), NSGs (Azure). Rules: allow/deny based on source/destination IP, port, protocol. Best practice: deny all by default, allow only necessary traffic. WAFs protect against SQL injection, XSS.", category: "Security", difficulty: "EASY" as const, tags: ["firewall", "security", "networking"] },
  { questionText: "What is Kubernetes at a high level?", idealAnswer: "Kubernetes (K8s) is a container orchestration platform that automates deployment, scaling, and management of containerized applications. Key concepts: Pods (smallest unit, one or more containers), Deployments (desired state management), Services (networking/load balancing), Namespaces (isolation). It handles: auto-scaling, self-healing (restart failed containers), rolling updates, service discovery, secret management. Managed versions: EKS (AWS), GKE (Google), AKS (Azure).", category: "Kubernetes", difficulty: "EASY" as const, tags: ["kubernetes", "orchestration", "containers"] },
  { questionText: "What is logging and what are logging best practices?", idealAnswer: "Logging records application events for debugging and monitoring. Best practices: use structured logging (JSON format), include correlation IDs, use appropriate log levels (ERROR, WARN, INFO, DEBUG), never log sensitive data (passwords, tokens), send logs to centralized system (ELK, Datadog, CloudWatch), set retention policies, include timestamps and context (userId, requestId). In containers: log to stdout/stderr, let the platform collect them.", category: "Observability", difficulty: "EASY" as const, tags: ["logging", "observability", "best-practices"] },
  { questionText: "What is the difference between a deployment and a release?", idealAnswer: "Deployment is the technical act of putting new code onto servers. Release is making the new code available to users. They can be decoupled: deploy code behind a feature flag (deployed but not released), then toggle the flag to release. Benefits: deploy anytime (low risk), release when ready, instant rollback by toggling flag, gradual rollouts. This separation reduces deployment anxiety and enables faster iteration.", category: "Deployment", difficulty: "EASY" as const, tags: ["deployment", "release", "feature-flags"] },
  { questionText: "What is a container image layer?", idealAnswer: "Docker images are built from layers — each instruction in a Dockerfile creates a layer. Layers are cached and shared between images, saving space and build time. If a layer hasn't changed, Docker reuses the cached version. Order matters: put frequently changing instructions (COPY code) after stable ones (COPY package.json, RUN npm install). Multi-stage builds keep final images small by discarding build layers.", category: "Containers", difficulty: "EASY" as const, tags: ["docker", "layers", "images"] },
  { questionText: "What is artifact management?", idealAnswer: "Artifacts are build outputs: Docker images, compiled binaries, npm packages, JAR files. Artifact management stores, versions, and distributes these. Tools: JFrog Artifactory, Nexus, GitHub Packages, npm registry, Docker registries. Benefits: immutable builds (same artifact through all environments), traceability (map artifacts to Git commits), dependency caching, access control. In CI/CD: build once, store in registry, deploy the same artifact everywhere.", category: "CI/CD", difficulty: "EASY" as const, tags: ["artifacts", "registry", "ci-cd"] },
  { questionText: "What is TLS/SSL and why is HTTPS important?", idealAnswer: "TLS (Transport Layer Security, successor to SSL) encrypts communication between client and server. HTTPS = HTTP + TLS. Provides: confidentiality (encrypted data), integrity (tamper detection), authentication (server identity via certificates). Essential for: protecting user data, preventing man-in-the-middle attacks, required for HTTP/2 and PWAs. Use Let's Encrypt for free certificates. Terminate TLS at the load balancer or reverse proxy.", category: "Security", difficulty: "EASY" as const, tags: ["tls", "https", "security"] },
  { questionText: "What is a health check endpoint?", idealAnswer: "A health check is an HTTP endpoint (typically `/health` or `/healthz`) that reports service status. Returns 200 if healthy, 503 if not. Types: liveness (is the process running?), readiness (can it handle traffic?). Used by: load balancers (route traffic away from unhealthy instances), Kubernetes (restart unhealthy pods), monitoring (alert on failures). Check dependencies: database connection, Redis connection, disk space. Keep health checks lightweight and fast.", category: "Monitoring", difficulty: "EASY" as const, tags: ["health-check", "monitoring", "reliability"] },
  { questionText: "What is Nginx and what is it used for?", idealAnswer: "Nginx is a high-performance web server and reverse proxy. Uses: serve static files, reverse proxy to application servers, load balancing, SSL termination, rate limiting, caching, HTTP/2. Event-driven architecture handles thousands of concurrent connections efficiently. Configuration: server blocks, location blocks, upstream blocks for load balancing. In DevOps: the most common entry point for web traffic before it reaches application servers.", category: "Infrastructure", difficulty: "EASY" as const, tags: ["nginx", "web-server", "proxy"] },
  { questionText: "What is the twelve-factor app methodology?", idealAnswer: "Twelve-factor is a methodology for building SaaS apps: (1) Codebase in version control, (2) Dependencies explicitly declared, (3) Config in environment variables, (4) Backing services as attached resources, (5) Strict build/release/run separation, (6) Stateless processes, (7) Port binding for services, (8) Concurrency via process model, (9) Disposability (fast startup/graceful shutdown), (10) Dev/prod parity, (11) Logs as event streams, (12) Admin tasks as one-off processes. These principles make apps cloud-native and container-friendly.", category: "Architecture", difficulty: "EASY" as const, tags: ["twelve-factor", "cloud-native", "architecture"] },
  { questionText: "What is cron and how do you schedule tasks in Linux?", idealAnswer: "Cron is Linux's task scheduler. Crontab entries follow: `minute hour day-of-month month day-of-week command`. Example: `0 2 * * * /scripts/backup.sh` runs at 2 AM daily. Edit with `crontab -e`. Special strings: @daily, @hourly, @weekly. Best practices: use absolute paths, redirect output to log files, handle failures with alerts. Modern alternatives: systemd timers (Linux), Kubernetes CronJobs (containers), cloud schedulers (AWS EventBridge).", category: "Linux", difficulty: "EASY" as const, tags: ["cron", "linux", "scheduling"] },
  // ===== MEDIUM (40 questions) =====
  { questionText: "Explain the differences between blue-green, canary, and rolling deployments.", idealAnswer: "Blue-green: two identical environments; switch traffic from blue (old) to green (new) instantly. Canary: gradually shift a small percentage of traffic to the new version, monitor, increase if healthy. Rolling: replace instances one-by-one until all run the new version (Kubernetes default). Blue-green: safest rollback (instant switch back), but requires double infrastructure. Canary: catches issues with minimal user impact. Rolling: most resource-efficient but slower rollback. Choose based on risk tolerance and infrastructure budget.", category: "Deployment", difficulty: "MEDIUM" as const, tags: ["deployment", "blue-green", "canary"] },
  { questionText: "How does Kubernetes handle service discovery and networking?", idealAnswer: "Service discovery: Kubernetes Services provide stable DNS names and IPs for pods. CoreDNS resolves service names to ClusterIPs. Types: ClusterIP (internal), NodePort (external via node ports), LoadBalancer (cloud LB). Networking: every pod gets a unique IP, pods communicate directly without NAT. Network policies control traffic between pods. Ingress controllers (Nginx Ingress) handle external HTTP routing with path-based rules and TLS termination.", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["kubernetes", "networking", "services"] },
  { questionText: "What is Terraform and how does it manage infrastructure state?", idealAnswer: "Terraform is a declarative IaC tool that provisions infrastructure across clouds. You define desired state in HCL files; Terraform calculates the plan to reach that state. State file (terraform.tfstate) tracks current infrastructure. Remote state (S3 + DynamoDB lock) enables team collaboration. Workflow: `terraform init` → `terraform plan` → `terraform apply`. State enables: drift detection, dependency graph, change planning. Never edit state manually; use `terraform import` for existing resources.", category: "IaC", difficulty: "MEDIUM" as const, tags: ["terraform", "iac", "state-management"] },
  { questionText: "How do you implement secrets management in a production environment?", idealAnswer: "Never store secrets in code or Git. Solutions: (1) HashiCorp Vault: centralized secret management with dynamic secrets, access policies, audit logging, (2) AWS Secrets Manager/SSM Parameter Store: cloud-native, auto-rotation, (3) Kubernetes Secrets (base64, not encrypted by default — use Sealed Secrets or external-secrets-operator), (4) SOPS: encrypted files in Git. Best practices: rotate secrets regularly, use short-lived tokens, audit access, use service accounts with minimal permissions, encrypt at rest.", category: "Security", difficulty: "MEDIUM" as const, tags: ["secrets", "security", "vault"] },
  { questionText: "Explain container orchestration and why Kubernetes is the standard.", idealAnswer: "Container orchestration automates deployment, scaling, networking, and lifecycle management of containers. Kubernetes became the standard because: (1) Declarative configuration (desired state), (2) Self-healing (restarts failed containers), (3) Auto-scaling (HPA based on CPU/memory), (4) Rolling updates with zero downtime, (5) Service discovery and load balancing, (6) Huge ecosystem (Helm charts, operators), (7) Cloud-provider support (EKS, GKE, AKS). Alternatives: Docker Swarm (simpler, less features), Nomad (HashiCorp), ECS (AWS-specific).", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["kubernetes", "orchestration", "containers"] },
  { questionText: "How do you design a CI/CD pipeline for a microservices architecture?", idealAnswer: "Design: (1) Monorepo or polyrepo — affects trigger logic, (2) Per-service pipelines triggered by path changes, (3) Shared pipeline templates for consistency, (4) Stages: lint → test → build Docker image → push to registry → deploy to staging → integration tests → deploy to production, (5) Environment promotion (staging → production), (6) Dependency management between services (contract testing), (7) Parallel execution where possible, (8) Infrastructure changes in separate pipelines. Use: feature branches for development, main for deployment, semantic versioning for images.", category: "CI/CD", difficulty: "MEDIUM" as const, tags: ["ci-cd", "microservices", "pipeline"] },
  { questionText: "What is GitOps and how does it work?", idealAnswer: "GitOps uses Git as the single source of truth for declarative infrastructure. Principles: all config in Git, changes via pull requests, automated sync between Git and cluster. Tools: ArgoCD, Flux. Workflow: developer pushes manifest change → PR reviewed → merged → ArgoCD detects change → syncs cluster state to match Git. Benefits: audit trail (Git history), easy rollback (git revert), declarative (desired state), consistent environments. Pull-based model: agent in cluster pulls from Git, more secure than CI pushing to cluster.", category: "GitOps", difficulty: "MEDIUM" as const, tags: ["gitops", "argocd", "kubernetes"] },
  { questionText: "How do you monitor a Kubernetes cluster effectively?", idealAnswer: "Layers: (1) Infrastructure: node CPU/memory/disk (Prometheus node_exporter), (2) Kubernetes: pod status, restarts, resource utilization (kube-state-metrics), (3) Application: request rate, error rate, latency (application metrics via Prometheus client libraries), (4) Logs: centralized logging (Loki, EFK stack), (5) Traces: distributed tracing (Jaeger, Tempo). Dashboard: Grafana with pre-built K8s dashboards. Alerts: pod CrashLoopBackOff, high error rates, resource exhaustion, PVC filling up. Use Prometheus + Grafana + Alertmanager as the standard stack.", category: "Monitoring", difficulty: "MEDIUM" as const, tags: ["kubernetes", "monitoring", "prometheus"] },
  { questionText: "Explain the concept of immutable infrastructure.", idealAnswer: "Immutable infrastructure never modifies running servers — instead, build a new image with changes and replace the old one. Benefits: no configuration drift, reproducible deployments, easy rollback (switch to previous image), consistent environments. Implementation: Packer builds VM/AMI images, Docker builds container images, Terraform provisions new instances. Contrast with mutable infrastructure (SSH in and modify) which leads to snowflake servers. Immutable + IaC + CI/CD = reliable deployments.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["immutable", "infrastructure", "patterns"] },
  { questionText: "How do you handle database migrations in a CI/CD pipeline?", idealAnswer: "Strategies: (1) Run migrations as a pre-deploy step in the pipeline, (2) Use a migration tool (Prisma Migrate, Flyway, Alembic) that tracks applied migrations, (3) Backward-compatible migrations only (expand-contract pattern), (4) Never drop columns in the same deploy as code changes, (5) Test migrations on a staging database first, (6) Kubernetes: use init containers or Job resources for migrations, (7) Lock mechanism to prevent concurrent migrations, (8) Automated rollback plan. Always: version migration files, review in PRs, test on production-sized data.", category: "CI/CD", difficulty: "MEDIUM" as const, tags: ["migrations", "database", "ci-cd"] },
  { questionText: "What is Prometheus and how does it collect metrics?", idealAnswer: "Prometheus is an open-source monitoring system using a pull model — it scrapes HTTP endpoints (/metrics) at configured intervals. Data model: time-series with labels (key-value pairs). Metric types: counter (monotonically increasing), gauge (can go up/down), histogram (bucketed distributions), summary (quantiles). PromQL queries data for dashboards and alerts. Architecture: Prometheus server → scrapes targets → stores time-series → Alertmanager for notifications → Grafana for visualization. Service discovery integrates with Kubernetes automatically.", category: "Monitoring", difficulty: "MEDIUM" as const, tags: ["prometheus", "metrics", "monitoring"] },
  { questionText: "How do you implement log aggregation for distributed systems?", idealAnswer: "Architecture: (1) Applications log to stdout (containers), (2) Log collector (Fluentd, Filebeat, Promtail) ships logs to central store, (3) Central store: Elasticsearch (ELK), Loki (Grafana), CloudWatch. (4) Visualization: Kibana, Grafana. Best practices: structured JSON logging, correlation IDs for request tracing, consistent log levels, index by service/date, set retention policies. In Kubernetes: DaemonSet runs log collector on each node, automatically collects pod stdout. Alert on: error rate spikes, specific error patterns.", category: "Observability", difficulty: "MEDIUM" as const, tags: ["logging", "elk", "observability"] },
  { questionText: "What is Helm and how does it help manage Kubernetes applications?", idealAnswer: "Helm is a package manager for Kubernetes. Charts are packages of K8s manifests with templates and default values. Benefits: reusable deployments, parameterized with values.yaml, versioned releases, easy rollback (`helm rollback`), dependency management between charts. Workflow: `helm install myapp ./chart --values prod-values.yaml`. Chart structure: templates/ (K8s manifests with Go templates), values.yaml (defaults), Chart.yaml (metadata). Helm repositories share charts. Use for: standardized deployments, environment-specific configurations.", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["helm", "kubernetes", "packaging"] },
  { questionText: "How do you implement zero-downtime deployments?", idealAnswer: "Requirements: (1) Rolling updates: replace pods gradually (Kubernetes default), configure maxSurge and maxUnavailable, (2) Readiness probes: don't route traffic until pod is ready, (3) Graceful shutdown: handle SIGTERM, drain connections, (4) Backward-compatible changes: new code works with old database schema, (5) Database migrations: expand-contract pattern, (6) Health checks: load balancer verifies instances before routing, (7) Pre-stop hooks for connection draining. Test: deploy during peak traffic in staging. Monitor error rates during rollout; auto-rollback if errors spike.", category: "Deployment", difficulty: "MEDIUM" as const, tags: ["zero-downtime", "deployment", "rolling-update"] },
  { questionText: "What is a service mesh and when would you use one?", idealAnswer: "A service mesh manages service-to-service communication with a sidecar proxy (Envoy) beside each pod. Features: mutual TLS (automatic encryption), traffic management (canary routing, retries, circuit breaking), observability (metrics, tracing without code changes), access policies. Tools: Istio, Linkerd, Consul Connect. Use when: many microservices need consistent security/observability, traffic management requirements are complex. Trade-off: adds complexity, resource overhead. Don't use for simple architectures.", category: "Networking", difficulty: "MEDIUM" as const, tags: ["service-mesh", "istio", "microservices"] },
  { questionText: "How do you manage Kubernetes configuration across multiple environments?", idealAnswer: "Approaches: (1) Kustomize: base + overlays per environment (dev, staging, prod) — built into kubectl, (2) Helm values files: values-dev.yaml, values-prod.yaml per environment, (3) GitOps with ArgoCD: separate branches or directories per environment, (4) Sealed Secrets or external-secrets for environment-specific secrets. Best practices: keep base configuration DRY, only override what differs (replicas, resources, URLs), use namespaces for isolation, tag images with specific versions (never use latest in production).", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["kubernetes", "configuration", "environments"] },
  { questionText: "Explain the concept of chaos engineering.", idealAnswer: "Chaos engineering deliberately injects failures into production systems to test resilience. Principles: define steady state (normal metrics), hypothesize that the system handles the failure, introduce chaos (kill pods, network latency, disk pressure), observe results, fix weaknesses. Tools: Chaos Monkey (Netflix), Litmus Chaos (Kubernetes), Gremlin. Start small: kill one pod, then increase scope. Prerequisites: monitoring in place, rollback capability. Benefits: discover failure modes before they happen in production.", category: "Reliability", difficulty: "MEDIUM" as const, tags: ["chaos-engineering", "resilience", "testing"] },
  { questionText: "What is the difference between stateful and stateless applications in containers?", idealAnswer: "Stateless apps don't store data locally — any instance can handle any request. Ideal for containers: easy to scale, replace, and load balance. Stateful apps maintain data (databases, message queues). In Kubernetes: Deployments for stateless, StatefulSets for stateful (stable network identity, persistent volumes, ordered deployment). Best practice: make apps stateless by externalizing state to databases, Redis, S3. This enables horizontal scaling and zero-downtime deployments.", category: "Architecture", difficulty: "MEDIUM" as const, tags: ["stateful", "stateless", "kubernetes"] },
  { questionText: "How do you handle persistent storage in Kubernetes?", idealAnswer: "Kubernetes storage: PersistentVolume (PV) is the actual storage, PersistentVolumeClaim (PVC) is a request for storage. StorageClasses define dynamic provisioning (automatically create PVs). Access modes: ReadWriteOnce (single node), ReadOnlyMany, ReadWriteMany. In cloud: EBS (AWS), Persistent Disks (GCP). For databases: use StatefulSets with PVCs for stable storage. For shared files: use NFS or EFS. Backup PVs regularly. CSI drivers enable different storage backends.", category: "Kubernetes", difficulty: "MEDIUM" as const, tags: ["kubernetes", "storage", "persistent-volumes"] },
  { questionText: "What is Ansible and how does it differ from Terraform?", idealAnswer: "Ansible is an agentless configuration management tool using SSH. It configures existing servers (install packages, update configs, deploy apps). Terraform provisions infrastructure (create servers, networks, databases). Ansible: procedural (tasks in order), idempotent modules, YAML playbooks. Terraform: declarative (desired state), state file, HCL. Use together: Terraform creates infrastructure, Ansible configures it. Terraform for cloud resources, Ansible for server configuration. Both support dry-run modes.", category: "IaC", difficulty: "MEDIUM" as const, tags: ["ansible", "terraform", "configuration-management"] },
  { questionText: "How do you implement auto-scaling in cloud environments?", idealAnswer: "Types: (1) Horizontal Pod Autoscaler (HPA): scales pods based on CPU/memory/custom metrics, (2) Vertical Pod Autoscaler (VPA): adjusts pod resource requests, (3) Cluster Autoscaler: adds/removes nodes based on pending pods, (4) Cloud auto-scaling groups (AWS ASG): scale EC2 instances by metrics. Configuration: set min/max replicas, target utilization (e.g., 70% CPU), cooldown periods. Custom metrics: scale on request queue depth, response time. Test: load test to verify scaling behavior. Combine HPA + Cluster Autoscaler for full auto-scaling.", category: "Scaling", difficulty: "MEDIUM" as const, tags: ["auto-scaling", "kubernetes", "hpa"] },
  { questionText: "What are GitHub Actions and how do you set up a workflow?", idealAnswer: "GitHub Actions is CI/CD built into GitHub. Workflows are YAML files in `.github/workflows/`. Components: triggers (on push, PR, schedule), jobs (run on runners), steps (individual tasks). Example: on PR → run tests → build Docker image → push to registry. Features: matrix builds (test across versions), caching (npm, Docker layers), secrets management, reusable workflows, marketplace actions. Best practices: pin action versions, use caching, fail fast, keep workflows focused.", category: "CI/CD", difficulty: "MEDIUM" as const, tags: ["github-actions", "ci-cd", "automation"] },
  { questionText: "How do you secure a Docker container?", idealAnswer: "Practices: (1) Use minimal base images (Alpine, distroless), (2) Run as non-root user (USER directive), (3) Scan for vulnerabilities (Trivy, Snyk), (4) Don't store secrets in images (use env vars or secret managers), (5) Use multi-stage builds (no build tools in production image), (6) Set read-only filesystem where possible, (7) Limit capabilities (drop all, add only needed), (8) Pin base image versions (no :latest), (9) Use .dockerignore, (10) Sign images (Docker Content Trust). In Kubernetes: use PodSecurityPolicies or OPA Gatekeeper.", category: "Security", difficulty: "MEDIUM" as const, tags: ["docker", "security", "containers"] },
  { questionText: "What is the difference between observability and monitoring?", idealAnswer: "Monitoring tracks predefined metrics and alerts when thresholds are breached — it answers known questions. Observability is the ability to understand internal system state from external outputs — it enables asking new questions. Three pillars of observability: metrics (quantitative), logs (qualitative events), traces (request flows). Monitoring is a subset of observability. Modern systems need observability because microservices create unpredictable failure modes that monitoring alone can't diagnose.", category: "Observability", difficulty: "MEDIUM" as const, tags: ["observability", "monitoring", "pillars"] },
  { questionText: "How do you manage DNS for a production application?", idealAnswer: "Practices: (1) Use a DNS provider with high availability (Route53, Cloudflare), (2) Configure A/AAAA records for services, CNAME for aliases, (3) Use low TTLs during migrations (5 min), higher for stable records (1 hour), (4) Health-checked DNS for failover (Route53 health checks), (5) Geo-routing for multi-region (route to nearest region), (6) Weighted routing for gradual traffic shifting, (7) CAA records for certificate authority authorization, (8) DNSSEC for security. Manage DNS as code (Terraform) for auditability.", category: "Networking", difficulty: "MEDIUM" as const, tags: ["dns", "networking", "infrastructure"] },
  { questionText: "Explain the concept of Site Reliability Engineering (SRE).", idealAnswer: "SRE applies software engineering practices to operations. Key concepts: (1) SLIs (Service Level Indicators) — measured metrics (latency, availability), (2) SLOs (Service Level Objectives) — targets for SLIs (99.9% uptime), (3) SLAs (Service Level Agreements) — contractual guarantees with consequences, (4) Error budgets — allowed failure margin (0.1% downtime = 43 min/month), spend it on feature velocity, (5) Toil reduction — automate repetitive operational tasks, (6) Blameless postmortems. SRE balances reliability with development speed using error budgets.", category: "SRE", difficulty: "MEDIUM" as const, tags: ["sre", "reliability", "slo"] },
  { questionText: "How do you implement disaster recovery for a production system?", idealAnswer: "Strategy: (1) Define RTO (Recovery Time Objective) and RPO (Recovery Point Objective), (2) Automated backups with tested restores (backup that's never tested is not a backup), (3) Multi-AZ deployment for high availability, (4) Cross-region replication for disaster recovery, (5) Infrastructure as code for rapid re-provisioning, (6) Documented runbooks for recovery procedures, (7) Regular DR drills, (8) Monitoring with alerts for backup failures. Tiers: hot standby (instant failover), warm standby (minutes), cold (hours). Cost increases with faster recovery.", category: "Reliability", difficulty: "MEDIUM" as const, tags: ["disaster-recovery", "reliability", "backup"] },
  { questionText: "What is container networking and how does Docker networking work?", idealAnswer: "Docker networks enable container communication. Types: bridge (default, containers on same host), host (shares host network), overlay (multi-host, Docker Swarm/K8s), none (isolated). Bridge: containers communicate via container names as DNS. Port mapping: `-p 8080:3000` maps host 8080 to container 3000. In Kubernetes: each pod gets a unique IP, CNI plugins (Calico, Cilium) handle networking. Network policies restrict pod-to-pod traffic. Service mesh adds encryption and routing.", category: "Networking", difficulty: "MEDIUM" as const, tags: ["docker", "networking", "containers"] },
  { questionText: "How do you optimize Docker images for production?", idealAnswer: "Techniques: (1) Multi-stage builds: build in one stage, copy only artifacts to final stage, (2) Minimal base images: Alpine (~5MB) or distroless, (3) Combine RUN commands to reduce layers, (4) Order instructions by change frequency (dependencies before code), (5) Use .dockerignore to exclude unnecessary files, (6) Pin specific versions (not :latest), (7) Remove package caches in same RUN step, (8) Scan for vulnerabilities (Trivy). A typical Node.js production image should be 100-200MB, not 1GB. Smaller images = faster pulls and deploys.", category: "Containers", difficulty: "MEDIUM" as const, tags: ["docker", "optimization", "images"] },
  { questionText: "What is infrastructure drift and how do you prevent it?", idealAnswer: "Infrastructure drift occurs when actual infrastructure state diverges from the defined state (code). Causes: manual changes, failed applies, out-of-band modifications. Prevention: (1) Strict IaC — all changes through code, never manual, (2) Terraform plan in CI to detect drift, (3) Drift detection tools (Terraform Cloud, AWS Config), (4) Lock down direct access (read-only console, no SSH in production), (5) Automated remediation: re-apply desired state on drift detection. Culture: enforce that all changes go through Git PRs, no 'quick fixes' in the console.", category: "IaC", difficulty: "MEDIUM" as const, tags: ["drift", "iac", "terraform"] },
  // ===== HARD (30 questions) =====
  { questionText: "Design a highly available multi-region deployment architecture.", idealAnswer: "Architecture: (1) Global load balancer (AWS Global Accelerator, Cloudflare) routes to nearest region, (2) Per-region: multiple AZs with auto-scaling groups behind ALB, (3) Database: primary in one region with cross-region read replicas, or multi-primary (CockroachDB, Aurora Global), (4) Cache: Redis Cluster per region, (5) Object storage: S3 with cross-region replication, (6) DNS: Route53 latency-based routing with health checks, (7) CDN: CloudFront for static assets globally. Challenges: data consistency across regions, conflict resolution, compliance (data residency). Active-active for reads everywhere; writes to primary or use conflict-free replication.", category: "Architecture", difficulty: "HARD" as const, tags: ["multi-region", "high-availability", "architecture"] },
  { questionText: "How would you implement a zero-trust security model for infrastructure?", idealAnswer: "Principles: never trust, always verify. Implementation: (1) Identity-based access: authenticate and authorize every request (mutual TLS via service mesh), (2) Network micro-segmentation: Kubernetes network policies, firewall rules per service, (3) Least privilege: RBAC with minimal permissions, short-lived credentials, (4) Secrets: dynamic secrets via Vault (database credentials generated per request with TTL), (5) Device trust: verified machines only, (6) Continuous verification: re-validate permissions at every request, (7) Encryption: in-transit (mTLS) and at-rest, (8) Audit: log all access decisions. No implicit trust from network location.", category: "Security", difficulty: "HARD" as const, tags: ["zero-trust", "security", "architecture"] },
  { questionText: "Design a comprehensive incident management and postmortem process.", idealAnswer: "Incident management: (1) Detection: automated alerts (PagerDuty) based on SLO breaches, (2) Triage: severity levels (SEV1-4) with defined response times, (3) Incident commander coordinates response, (4) Communication: status page updates, internal Slack channel, (5) Mitigation: fix the immediate issue (rollback, scale, failover), (6) Resolution: root cause fix deployed. Postmortem: blameless document within 48 hours — timeline, root causes (5 Whys), impact metrics, action items with owners and deadlines. Review in team meeting. Track action item completion. Publish internally to share learnings.", category: "SRE", difficulty: "HARD" as const, tags: ["incident-management", "postmortem", "sre"] },
  { questionText: "Explain how to implement a secure and automated certificate management system.", idealAnswer: "Architecture: (1) ACME protocol with Let's Encrypt for public certificates, (2) cert-manager in Kubernetes: automatically provisions, renews TLS certificates, stores in Secrets, (3) Internal CA (Vault PKI) for service-to-service mTLS certificates, (4) Short-lived certificates (24h-90 days) auto-rotated, (5) Certificate monitoring: alert before expiry, (6) Certificate transparency monitoring for unauthorized issuance. Workflow: cert-manager watches Ingress/Certificate resources → requests from Let's Encrypt/Vault → stores in K8s Secrets → Nginx/Envoy picks up automatically. Never manually manage certificates.", category: "Security", difficulty: "HARD" as const, tags: ["certificates", "tls", "cert-manager"] },
  { questionText: "How would you design a platform engineering team's internal developer platform?", idealAnswer: "Components: (1) Self-service portal: developers create services, databases, environments without tickets, (2) Golden paths: templated service scaffolding (Backstage), (3) CI/CD templates: standardized pipelines developers inherit, (4) Infrastructure abstraction: developers specify 'I need a database' not 'create RDS with these 50 settings', (5) Observability: auto-instrumented logging, metrics, tracing, (6) Security: automated scanning, policy enforcement, (7) Documentation: service catalog (Backstage), runbooks. Build on: Kubernetes, Terraform, ArgoCD, Backstage. Goal: reduce cognitive load for developers while maintaining security and reliability standards.", category: "Architecture", difficulty: "HARD" as const, tags: ["platform-engineering", "developer-experience", "architecture"] },
  { questionText: "How do you implement GitOps at scale with multiple clusters and teams?", idealAnswer: "Architecture: (1) Repository structure: mono-repo with app-of-apps pattern or poly-repo with fleet management, (2) ArgoCD ApplicationSets for templating across clusters, (3) Kustomize overlays per cluster/environment, (4) RBAC: team-scoped ArgoCD projects, namespace isolation, (5) Secret management: Sealed Secrets or external-secrets-operator, (6) Promotion: automated PRs from staging to production repo, (7) Drift detection: ArgoCD auto-sync or manual sync with approval, (8) Multi-cluster: ArgoCD managing remote clusters, or fleet management (Rancher Fleet). Policy enforcement: OPA Gatekeeper validates manifests pre-sync.", category: "GitOps", difficulty: "HARD" as const, tags: ["gitops", "argocd", "multi-cluster"] },
  { questionText: "Design a comprehensive backup and disaster recovery strategy for a Kubernetes-based platform.", idealAnswer: "Strategy: (1) Application data: database backups (pg_dump, WAL archiving for PITR), object storage versioning, (2) Kubernetes state: Velero for cluster backup (resources + PVs), etcd snapshots, (3) Infrastructure: Terraform state in versioned S3, IaC enables re-provisioning, (4) RPO/RTO targets per tier (critical: RPO 1h, RTO 4h), (5) Cross-region: replicate backups to another region, (6) Testing: monthly DR drills — restore to a new cluster, verify data, (7) Automation: backup verification jobs that restore and validate, (8) Runbooks: documented step-by-step recovery procedures. Never assume backups work — verify regularly.", category: "Reliability", difficulty: "HARD" as const, tags: ["backup", "disaster-recovery", "kubernetes"] },
  { questionText: "How do you implement policy as code for infrastructure governance?", idealAnswer: "Implementation: (1) OPA (Open Policy Agent) with Rego for general policy evaluation, (2) Kubernetes: OPA Gatekeeper or Kyverno for admission control (enforce labels, image sources, resource limits), (3) Terraform: Sentinel (HashiCorp) or Conftest (OPA) to validate plans before apply, (4) CI pipeline: policy checks as mandatory gates, (5) Policies: no containers as root, images only from approved registries, resources must have cost tags, no public S3 buckets. Store policies in Git, version and review like code. Start with audit mode (warn), then enforce. Exceptions via documented approval process.", category: "Security", difficulty: "HARD" as const, tags: ["policy-as-code", "opa", "governance"] },
  { questionText: "Explain how to build a multi-tenant Kubernetes platform.", idealAnswer: "Isolation levels: (1) Namespace per tenant: cheapest, weakest isolation. Use RBAC, ResourceQuotas, LimitRanges, NetworkPolicies, (2) Virtual clusters (vcluster): stronger isolation, each tenant gets a virtual API server, (3) Separate clusters per tenant: strongest isolation, highest cost. Implementation: (1) Admission controllers enforce tenant labels, (2) Network policies restrict cross-namespace traffic, (3) Resource quotas prevent noisy neighbors, (4) RBAC scopes access to tenant namespace, (5) Separate node pools per tenant (for compliance), (6) Monitoring/logging per tenant. Consider: cost allocation, noisy neighbor prevention, security boundary requirements.", category: "Kubernetes", difficulty: "HARD" as const, tags: ["multi-tenancy", "kubernetes", "platform"] },
  { questionText: "How would you implement progressive delivery with Argo Rollouts?", idealAnswer: "Argo Rollouts extends Kubernetes Deployments with advanced deployment strategies. Setup: (1) Install Argo Rollouts controller, (2) Replace Deployment with Rollout resource, (3) Canary strategy: define steps (10% → 30% → 60% → 100%), pause durations, (4) Analysis: automated metric checks at each step (Prometheus queries — error rate < 1%, latency P99 < 500ms), (5) Auto-promote on success, auto-rollback on analysis failure, (6) Traffic management via Istio, Nginx, or ALB for weighted routing. Blue-green: promote/abort based on analysis. Integrates with GitOps (ArgoCD triggers Rollout).", category: "Deployment", difficulty: "HARD" as const, tags: ["argo-rollouts", "progressive-delivery", "canary"] },
  { questionText: "Design a CI/CD pipeline for infrastructure changes with proper safeguards.", idealAnswer: "Pipeline: (1) PR trigger: `terraform plan` runs automatically, comments plan diff on PR, (2) Manual approval required for production changes, (3) Policy checks: OPA/Sentinel validates plan (no security group 0.0.0.0/0, required tags), (4) Cost estimation: Infracost predicts cost impact, (5) Merge to main: `terraform apply` with state locking, (6) Post-apply: drift detection scheduled, (7) Blast radius limits: workspace per environment, separate pipelines for critical infrastructure. Safeguards: require 2 approvals for production, prevent destroy of databases, separate state files, version-locked providers.", category: "CI/CD", difficulty: "HARD" as const, tags: ["terraform", "ci-cd", "infrastructure"] },
  { questionText: "How do you implement observability for a microservices system?", idealAnswer: "Three pillars integration: (1) Metrics: Prometheus + Grafana — RED method per service (Rate, Errors, Duration), USE method for infrastructure (Utilization, Saturation, Errors), (2) Logs: Loki/ELK — structured JSON, correlation IDs linking to traces, (3) Traces: OpenTelemetry SDK → Jaeger/Tempo — end-to-end request visualization. Correlation: trace ID in logs and metric exemplars for seamless navigation. Dashboards: service-level (SLO dashboard), system-level (cluster health), business-level (transaction volume). Alerts: SLO-based (error budget consumption rate), not threshold-based where possible.", category: "Observability", difficulty: "HARD" as const, tags: ["observability", "opentelemetry", "microservices"] },
  { questionText: "How would you design auto-remediation for common infrastructure failures?", idealAnswer: "Architecture: (1) Detection: monitoring alerts (Prometheus Alertmanager), (2) Decision: runbook automation determines response (PagerDuty Rundeck, StackStorm), (3) Actions: pre-defined remediation scripts for known issues, (4) Examples: restart crashed pods (K8s self-healing), scale up on high CPU (HPA), failover database on primary failure, clear full disk logs, rotate expired certificates, (5) Escalation: auto-remediation attempts first, escalate to human if fails, (6) Safety: circuit breaker on remediation (don't retry indefinitely), blast radius limits, audit log of all automated actions. Start with read-only automation (diagnostics), gradually add write actions.", category: "SRE", difficulty: "HARD" as const, tags: ["auto-remediation", "sre", "automation"] },
  { questionText: "Explain how to implement a secure software supply chain.", idealAnswer: "Practices: (1) Source: signed commits, branch protection, code review requirements, (2) Dependencies: SCA scanning (Dependabot, Snyk), pinned versions, private mirrors, (3) Build: reproducible builds, build provenance (SLSA framework), signed artifacts, (4) Images: vulnerability scanning (Trivy), signed images (Cosign/Notary), minimal base images, (5) Deploy: admission controller verifies image signatures, only approved registries, (6) Runtime: read-only filesystem, no exec into production containers. Framework: SLSA (Supply-chain Levels for Software Artifacts) levels 1-4. Monitor: track all components, alert on new CVEs affecting deployed software.", category: "Security", difficulty: "HARD" as const, tags: ["supply-chain", "security", "slsa"] },
  { questionText: "How would you migrate a legacy monolith deployment to Kubernetes?", idealAnswer: "Strategy: (1) Assess: containerize the monolith first (lift-and-shift), get it running in K8s, (2) Set up CI/CD: automated build, test, deploy pipeline, (3) Add observability: logging, metrics, health checks to the monolith, (4) Strangler fig pattern: extract services one by one, route traffic gradually, (5) State management: externalize sessions to Redis, files to S3, (6) Database: keep shared initially, migrate to per-service databases later, (7) Networking: API gateway routes between monolith and new services, (8) Testing: run both in parallel, compare responses. Timeline: months to years depending on size. Don't rewrite everything at once.", category: "Architecture", difficulty: "HARD" as const, tags: ["migration", "kubernetes", "monolith"] },
  { questionText: "Design a cost optimization strategy for cloud infrastructure.", idealAnswer: "Strategy: (1) Visibility: tag all resources, implement cost allocation per team/service (AWS Cost Explorer, Kubecost), (2) Right-sizing: analyze utilization, downsize overprovisioned instances (80% CPU target), (3) Reserved/Savings plans: commit to 1-3 years for predictable workloads (30-60% savings), (4) Spot instances: for fault-tolerant workloads (CI runners, batch processing), (5) Auto-scaling: scale down during off-hours, (6) Storage: lifecycle policies (S3 tiers), delete unused volumes/snapshots, (7) Networking: reduce cross-AZ traffic, use VPC endpoints, (8) FinOps practices: regular cost reviews, budgets with alerts, team accountability. Implement gradually with automated cost anomaly detection.", category: "Cloud", difficulty: "HARD" as const, tags: ["cost-optimization", "finops", "cloud"] },
  { questionText: "How do you implement a robust secrets rotation strategy?", idealAnswer: "Implementation: (1) Vault dynamic secrets: generate unique database credentials per service with short TTL (1 hour), auto-revoked on expiry, (2) AWS Secrets Manager: automatic rotation for RDS, Redshift credentials on a schedule, (3) API keys: rotate via CI/CD — create new key, update deployment, verify, revoke old key, (4) TLS certificates: cert-manager auto-renews before expiry, (5) JWT signing keys: key rotation with overlap period (verify with old + new during transition), (6) Emergency rotation: automated runbook for compromised credentials — rotate across all services within minutes. Audit: log all secret access, alert on unusual patterns. Test rotation in staging regularly.", category: "Security", difficulty: "HARD" as const, tags: ["secrets-rotation", "vault", "security"] },
  { questionText: "How would you build a self-healing Kubernetes platform?", idealAnswer: "Layers: (1) Pod level: liveness probes restart unhealthy containers, readiness probes remove from service, (2) Deployment: replicas ensure desired count, PDB prevents too many pods being unavailable, (3) Node level: Cluster Autoscaler replaces failed nodes, node problem detector identifies issues, (4) Application: circuit breakers prevent cascade failures, retry with backoff, (5) Data: automated failover for databases (RDS Multi-AZ, Patroni for self-hosted), (6) Infrastructure: auto-replace unhealthy instances in ASG, (7) Operational: automated runbooks for known issues (StackStorm, Rundeck), (8) Chaos engineering: proactively discover failure modes. Each layer handles its scope; escalate to the next if unresolvable.", category: "Reliability", difficulty: "HARD" as const, tags: ["self-healing", "kubernetes", "reliability"] },
  { questionText: "Design a comprehensive security scanning pipeline for containers and infrastructure.", idealAnswer: "Pipeline stages: (1) Pre-commit: secrets scanning (gitleaks), (2) Build: SAST (Semgrep), dependency scanning (Snyk/Dependabot), license compliance, (3) Image build: Dockerfile linting (hadolint), image vulnerability scanning (Trivy/Grype), (4) Pre-deploy: Kubernetes manifest validation (kubesec, OPA), Terraform plan scanning (tfsec/checkov), (5) Runtime: container behavior monitoring (Falco), network anomaly detection, (6) Continuous: scheduled scans for new CVEs against deployed images, (7) Dashboard: aggregate findings, track remediation SLAs by severity. Block deployments for critical/high CVEs. Generate SBOM (Software Bill of Materials) for each image.", category: "Security", difficulty: "HARD" as const, tags: ["security-scanning", "devsecops", "pipeline"] },
  { questionText: "How do you implement effective SLOs and error budgets?", idealAnswer: "Implementation: (1) Define SLIs per service: availability (successful requests / total), latency (P99 < 500ms), correctness, (2) Set SLOs: 99.9% availability = 43 minutes downtime/month, (3) Error budget = 1 - SLO = 0.1% allowed failures, (4) Monitor: SLO dashboard showing remaining budget, burn rate, (5) Alerts: multi-window burn rate alerts (fast burn = immediate, slow burn = ticket), (6) Policy: when budget exhausted, freeze features and focus on reliability, (7) Review: monthly SLO review with stakeholders. Use Sloth or Google SLO generator for Prometheus-based SLOs. SLOs should be based on user experience, not internal metrics.", category: "SRE", difficulty: "HARD" as const, tags: ["slo", "error-budget", "sre"] },
  { questionText: "Explain how to implement a FinOps practice for cloud cost management.", idealAnswer: "FinOps framework: (1) Inform: cost visibility dashboards per team/service/environment, tag enforcement, showback/chargeback reports, (2) Optimize: reserved instances for stable workloads, spot for interruptible, right-sizing recommendations, storage tiering, (3) Operate: budgets with alerts, anomaly detection, regular cost reviews, team accountability. Tools: Kubecost (Kubernetes), AWS Cost Explorer + CUR, Infracost (IaC cost estimation). Culture: engineers own their costs, cost is a non-functional requirement, architecture reviews include cost assessment. Track: cost per transaction, unit economics improvement over time.", category: "Cloud", difficulty: "HARD" as const, tags: ["finops", "cost-management", "cloud"] },
  { questionText: "How would you design a logging and audit trail system for compliance?", idealAnswer: "Architecture: (1) Immutable audit log: append-only storage, separate from application database, (2) Capture: all authentication events, data access, configuration changes, administrative actions, (3) Fields: who (user/service), what (action), when (timestamp), where (IP, location), result (success/fail), (4) Transport: encrypted in transit, written before action completes, (5) Storage: tamper-evident (hash chains or write-once storage like S3 Object Lock), (6) Retention: based on compliance requirements (SOC 2: 1 year, HIPAA: 6 years), (7) Access: read-only for auditors, no delete permissions, (8) Monitoring: alert on suspicious patterns. Integrate with SIEM for real-time analysis.", category: "Security", difficulty: "HARD" as const, tags: ["audit-trail", "compliance", "security"] },
  { questionText: "How do you troubleshoot a Kubernetes pod that won't start?", idealAnswer: "Systematic approach: (1) `kubectl describe pod <name>`: check Events section for scheduling failures, image pull errors, resource constraints, (2) `kubectl logs <pod>`: check application logs, use `--previous` for crashed containers, (3) Common issues: ImagePullBackOff (wrong image/registry auth), CrashLoopBackOff (app crashes on start — check logs), Pending (insufficient resources, node affinity mismatch), OOMKilled (memory limit too low), (4) Init container failures: check init container logs separately, (5) `kubectl get events --sort-by=.lastTimestamp`: cluster-wide events, (6) Resource issues: check node capacity, PVC binding status, network policies. Use ephemeral debug containers for runtime debugging.", category: "Kubernetes", difficulty: "HARD" as const, tags: ["kubernetes", "troubleshooting", "debugging"] },
  { questionText: "Design a multi-cloud deployment strategy.", idealAnswer: "Strategy: (1) Abstraction layer: Terraform with provider-agnostic modules where possible, Kubernetes as the common runtime, (2) Networking: inter-cloud connectivity via VPN or dedicated interconnect, service mesh for cross-cloud communication, (3) Data: determine data gravity (keep data in one cloud, compute can be multi-cloud), (4) CI/CD: cloud-agnostic pipeline (GitHub Actions) deploying to multiple clusters, (5) Observability: centralized monitoring aggregating from all clouds, (6) Identity: federated identity across clouds (OIDC). Trade-offs: increased complexity, higher operations cost, vendor-specific features forfeited. Do multi-cloud for: compliance, negotiation leverage, DR, specific cloud strengths. Don't do it just to avoid lock-in.", category: "Architecture", difficulty: "HARD" as const, tags: ["multi-cloud", "architecture", "strategy"] },
  { questionText: "How would you implement a canary analysis system that automatically promotes or rolls back deployments?", idealAnswer: "Architecture: (1) Deployment: Argo Rollouts or Flagger manages canary, (2) Traffic splitting: Istio/Nginx splits a percentage to canary, (3) Metrics collection: Prometheus collects canary vs baseline metrics, (4) Analysis: compare canary vs baseline on key metrics — error rate, latency P50/P99, business metrics, (5) Statistical comparison: use Mann-Whitney U test or Bayesian analysis for significance, (6) Decision: auto-promote if all metrics within acceptable range for configured duration, auto-rollback if any critical metric degrades beyond threshold, (7) Notifications: Slack alerts on promotion/rollback with analysis summary. Kayenta (Netflix) or Argo Rollouts AnalysisRun for automated canary analysis.", category: "Deployment", difficulty: "HARD" as const, tags: ["canary-analysis", "progressive-delivery", "automation"] },
  { questionText: "How do you implement network security in a Kubernetes cluster?", idealAnswer: "Layers: (1) Pod level: NetworkPolicies (deny all by default, allow specific) using Calico/Cilium, (2) Service mesh: mTLS for encrypted pod-to-pod traffic (Istio, Linkerd), authorization policies, (3) Ingress: TLS termination, WAF integration (ModSecurity), rate limiting, (4) Egress: restrict outbound traffic (network policies, egress gateways), (5) Node level: security groups, OS hardening, (6) DNS: CoreDNS policies to prevent data exfiltration via DNS, (7) Runtime: Falco for detecting anomalous network behavior. Principle: micro-segmentation — each service can only communicate with its declared dependencies. Monitor: network flow logs for anomaly detection.", category: "Security", difficulty: "HARD" as const, tags: ["network-security", "kubernetes", "zero-trust"] },
  { questionText: "Explain how to build a scalable CI/CD infrastructure.", idealAnswer: "Architecture: (1) CI runners: auto-scaling worker pool (Kubernetes-based runners, AWS CodeBuild), (2) Caching: shared cache for dependencies (S3/GCS), Docker layer caching, remote build cache (Turborepo), (3) Parallelization: split tests across runners, parallel jobs for independent stages, (4) Artifact storage: immutable artifacts in registry, (5) Pipeline as code: reusable templates/shared libraries, (6) Queue management: priority queues for production vs feature branches, (7) Cost optimization: spot instances for CI, auto-scale to zero during off-hours, (8) Security: ephemeral runners (no persistent state), separate CI credentials, OIDC for cloud access. Monitor: build times, queue wait times, success rates, cost per build.", category: "CI/CD", difficulty: "HARD" as const, tags: ["ci-cd", "infrastructure", "scaling"] },
  { questionText: "How would you implement a comprehensive container runtime security strategy?", idealAnswer: "Strategy: (1) Build time: minimal images, vulnerability scanning, signed images, (2) Admission: OPA/Kyverno policies — no privileged containers, no host networking, approved registries only, required labels, (3) Runtime: Falco for behavioral detection (unexpected process execution, file access, network connections), seccomp profiles to limit syscalls, AppArmor/SELinux, (4) Network: network policies for micro-segmentation, (5) Monitoring: audit logs, container behavior baselines, anomaly detection, (6) Response: automated quarantine of compromised pods (network isolation), alert SOC, forensic data collection. Defense in depth: each layer catches what the previous missed.", category: "Security", difficulty: "HARD" as const, tags: ["container-security", "runtime", "falco"] },
];
