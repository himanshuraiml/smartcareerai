export const backendDeveloperQuestions = [
  // ===== EASY (30 questions) =====
  {
    questionText: "What is the difference between SQL and NoSQL databases?",
    idealAnswer: "SQL databases are relational, use structured tables with schemas, and support ACID transactions (PostgreSQL, MySQL). NoSQL databases are non-relational, schema-flexible, and optimized for specific patterns: document (MongoDB), key-value (Redis), column-family (Cassandra), graph (Neo4j). Choose SQL for structured data with complex queries; NoSQL for flexible schemas, horizontal scaling, or specialized access patterns.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["sql", "nosql", "databases"],
  },
  {
    questionText: "What is REST and what are its key principles?",
    idealAnswer: "REST (Representational State Transfer) is an architectural style for APIs. Key principles: stateless requests, resource-based URLs (nouns, not verbs), standard HTTP methods (GET, POST, PUT, DELETE), proper status codes, and consistent response format. Resources are identified by URIs, representations transfer state, and HATEOAS provides discoverability.",
    category: "APIs",
    difficulty: "EASY" as const,
    tags: ["rest", "api", "http"],
  },
  {
    questionText: "What are HTTP status codes? Name the main categories.",
    idealAnswer: "Status codes indicate request outcomes: 1xx (informational), 2xx (success — 200 OK, 201 Created, 204 No Content), 3xx (redirection — 301 Moved, 304 Not Modified), 4xx (client errors — 400 Bad Request, 401 Unauthorized, 403 Forbidden, 404 Not Found), 5xx (server errors — 500 Internal Error, 502 Bad Gateway, 503 Service Unavailable).",
    category: "HTTP",
    difficulty: "EASY" as const,
    tags: ["http", "status-codes", "api"],
  },
  {
    questionText: "What is middleware in Express.js?",
    idealAnswer: "Middleware functions have access to request, response, and the next function in the pipeline. They execute sequentially and can modify req/res, end the request cycle, or call `next()`. Types: application-level (`app.use`), router-level, error-handling (4 params), built-in (`express.json()`), and third-party (cors, helmet). Used for logging, auth, parsing, rate limiting.",
    category: "Node.js",
    difficulty: "EASY" as const,
    tags: ["express", "middleware", "nodejs"],
  },
  {
    questionText: "What is the difference between authentication and authorization?",
    idealAnswer: "Authentication verifies identity (who you are) — login with credentials, JWT, OAuth. Authorization determines permissions (what you can do) — role-based access control, policies. Authentication happens first; authorization follows. Example: logging in is authentication; checking if a user can delete a post is authorization.",
    category: "Security",
    difficulty: "EASY" as const,
    tags: ["security", "authentication", "authorization"],
  },
  {
    questionText: "What is an ORM? What are its advantages and disadvantages?",
    idealAnswer: "An ORM (Object-Relational Mapping) maps database tables to programming objects (Prisma, Sequelize, TypeORM). Advantages: type safety, no raw SQL, migrations, relations handling. Disadvantages: performance overhead, complex queries are harder, abstraction leaks, N+1 query problems. Use ORMs for CRUD operations; raw SQL for complex analytics queries.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["orm", "prisma", "databases"],
  },
  {
    questionText: "What is JSON Web Token (JWT) and how does it work?",
    idealAnswer: "JWT is a compact, URL-safe token with three base64-encoded parts: header (algorithm, type), payload (claims like userId, exp, iat), and signature (verifies integrity). The server signs the token with a secret; clients send it in Authorization headers. JWTs are stateless — the server doesn't need session storage. Downsides: can't be revoked without a blocklist, size grows with claims.",
    category: "Security",
    difficulty: "EASY" as const,
    tags: ["jwt", "authentication", "security"],
  },
  {
    questionText: "What is the difference between `PUT` and `PATCH` HTTP methods?",
    idealAnswer: "`PUT` replaces the entire resource — you must send all fields. `PATCH` partially updates a resource — only send changed fields. Example: updating a user's email — `PUT` requires sending the entire user object, `PATCH` only needs `{email: 'new@email.com'}`. Use `PUT` for full replacements, `PATCH` for partial updates.",
    category: "HTTP",
    difficulty: "EASY" as const,
    tags: ["http", "rest", "methods"],
  },
  {
    questionText: "What is environment variable management and why is it important?",
    idealAnswer: "Environment variables store configuration that varies between environments (dev, staging, production) — database URLs, API keys, ports. They separate config from code, prevent secrets in version control. Use `.env` files locally (dotenv), environment-specific configs in deployment (Docker, Kubernetes secrets). Never commit `.env` files; use `.env.example` as a template.",
    category: "DevOps",
    difficulty: "EASY" as const,
    tags: ["environment", "configuration", "security"],
  },
  {
    questionText: "What is CORS and how do you configure it in Express?",
    idealAnswer: "CORS (Cross-Origin Resource Sharing) controls which domains can access your API. Browsers block cross-origin requests by default. In Express, use the `cors` middleware: `app.use(cors({ origin: 'https://example.com', credentials: true }))`. Configure allowed origins, methods, headers, and credentials. For development, allow all origins; for production, whitelist specific domains.",
    category: "Security",
    difficulty: "EASY" as const,
    tags: ["cors", "express", "security"],
  },
  {
    questionText: "What is the difference between synchronous and asynchronous programming in Node.js?",
    idealAnswer: "Synchronous code blocks execution until complete — each line waits for the previous. Asynchronous code (callbacks, Promises, async/await) doesn't block — Node continues processing while waiting for I/O. Node.js is single-threaded with an event loop, making async essential for handling concurrent requests. Never use synchronous file I/O or blocking operations in request handlers.",
    category: "Node.js",
    difficulty: "EASY" as const,
    tags: ["nodejs", "async", "event-loop"],
  },
  {
    questionText: "What is database indexing and why is it important?",
    idealAnswer: "An index is a data structure (usually B-tree) that speeds up data retrieval by avoiding full table scans. Add indexes on columns used in WHERE, JOIN, and ORDER BY clauses. Trade-offs: indexes speed up reads but slow down writes (must update index on insert/update/delete) and use additional storage. Common types: B-tree (default), hash, GIN (full-text), partial indexes.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["databases", "indexing", "performance"],
  },
  {
    questionText: "What is the `package.json` `scripts` field used for in Node.js?",
    idealAnswer: "The `scripts` field defines CLI commands runnable via `npm run <name>`. Common scripts: `start` (production entry), `dev` (development with hot reload), `build` (compile TypeScript), `test`, `lint`, `migrate`. Scripts can chain with `&&` (sequential) or `&` (parallel). Pre/post hooks: `pretest` runs before `test`. Use tools like concurrently or npm-run-all for parallel scripts.",
    category: "Node.js",
    difficulty: "EASY" as const,
    tags: ["nodejs", "npm", "scripts"],
  },
  {
    questionText: "What is error handling in Express.js? How do you create an error middleware?",
    idealAnswer: "Express error middleware has 4 parameters: `(err, req, res, next)`. Place it after all routes. Catch async errors by wrapping handlers in try/catch or using a wrapper function. Return consistent error responses with status code, message, and optional details. Use custom error classes (AppError) with status codes. Always handle unhandled rejections and uncaught exceptions at the process level.",
    category: "Node.js",
    difficulty: "EASY" as const,
    tags: ["express", "error-handling", "nodejs"],
  },
  {
    questionText: "What is the difference between TCP and UDP?",
    idealAnswer: "TCP is connection-oriented, reliable (guarantees delivery and order), with flow control and error checking — used for HTTP, database connections, file transfers. UDP is connectionless, unreliable (no delivery guarantee), but faster with lower overhead — used for streaming, gaming, DNS, VoIP. Choose TCP when data integrity matters; UDP when speed matters more than reliability.",
    category: "Networking",
    difficulty: "EASY" as const,
    tags: ["networking", "tcp", "udp"],
  },
  {
    questionText: "What is a database migration and why use them?",
    idealAnswer: "Migrations are version-controlled schema changes (create tables, add columns, modify constraints). They ensure the database schema is reproducible across environments and developers. Tools like Prisma Migrate, Knex, or Flyway generate migration files from schema changes. Run forward to update, roll back to revert. Never manually alter production databases — always use migrations.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["databases", "migrations", "prisma"],
  },
  {
    questionText: "What is Docker and why use it for backend development?",
    idealAnswer: "Docker packages applications with their dependencies into lightweight containers that run consistently across environments. Benefits: reproducible builds, consistent dev/prod environments, easy dependency management, microservices isolation. A `Dockerfile` defines the image; `docker-compose.yml` orchestrates multiple containers (app + database + cache). Containers share the host OS kernel, making them lighter than VMs.",
    category: "DevOps",
    difficulty: "EASY" as const,
    tags: ["docker", "containers", "devops"],
  },
  {
    questionText: "What is Redis and what are common use cases?",
    idealAnswer: "Redis is an in-memory key-value data store. Common uses: caching (reduce DB load), session storage, rate limiting (sliding window counters), pub/sub messaging, leaderboards (sorted sets), queues (lists). It supports data types: strings, hashes, lists, sets, sorted sets, streams. Data persists with RDB snapshots or AOF logs. Extremely fast — sub-millisecond latency for most operations.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["redis", "caching", "databases"],
  },
  {
    questionText: "What is the purpose of a `.gitignore` file?",
    idealAnswer: "`.gitignore` specifies files and directories that Git should not track. Common entries: `node_modules/`, `.env`, `dist/`, `*.log`, IDE files (`.vscode/`, `.idea/`). Patterns use glob syntax. Files already tracked aren't affected — use `git rm --cached` to untrack them. Place `.gitignore` at the repo root. Never commit secrets, build artifacts, or dependency folders.",
    category: "Git",
    difficulty: "EASY" as const,
    tags: ["git", "gitignore", "version-control"],
  },
  {
    questionText: "What is input validation and why is it crucial for backends?",
    idealAnswer: "Input validation ensures data from clients meets expected format, type, and constraints before processing. It prevents SQL injection, XSS, buffer overflows, and data corruption. Validate at the API boundary: type checking, length limits, regex patterns, whitelisting. Use libraries like Zod, Joi, or class-validator. Never trust client input — validate server-side even if the frontend validates.",
    category: "Security",
    difficulty: "EASY" as const,
    tags: ["validation", "security", "zod"],
  },
  {
    questionText: "What is a webhook and how does it differ from polling?",
    idealAnswer: "A webhook is a user-defined HTTP callback — when an event occurs, the source sends a POST request to your URL. Polling repeatedly checks for updates at intervals. Webhooks are event-driven (real-time, efficient), while polling wastes resources checking when nothing changed. Use webhooks for: payment notifications (Stripe), CI/CD triggers (GitHub), chat integrations (Slack). Secure with signature verification.",
    category: "APIs",
    difficulty: "EASY" as const,
    tags: ["webhooks", "api", "events"],
  },
  {
    questionText: "What is the difference between a process and a thread?",
    idealAnswer: "A process is an independent execution unit with its own memory space. A thread is a lightweight unit within a process sharing the same memory. Processes provide isolation; threads enable parallelism within an application. Node.js is single-threaded for JavaScript execution but uses threads internally for I/O via libuv. Use worker threads for CPU-intensive tasks.",
    category: "Operating Systems",
    difficulty: "EASY" as const,
    tags: ["os", "processes", "threads"],
  },
  {
    questionText: "What are HTTP headers and name some important ones?",
    idealAnswer: "HTTP headers are key-value metadata sent with requests/responses. Important request headers: `Authorization` (credentials), `Content-Type` (body format), `Accept` (desired response format), `Cookie`. Important response headers: `Set-Cookie`, `Cache-Control`, `Content-Security-Policy`, `X-Request-ID` (tracing). Security headers: `Strict-Transport-Security`, `X-Content-Type-Options`, `X-Frame-Options`.",
    category: "HTTP",
    difficulty: "EASY" as const,
    tags: ["http", "headers", "security"],
  },
  {
    questionText: "What is connection pooling in database management?",
    idealAnswer: "Connection pooling maintains a cache of reusable database connections instead of creating a new one per request. This reduces connection overhead (TCP handshake, auth) and limits max connections. Prisma, pg-pool, and most ORMs manage pools automatically. Configure min/max pool size, idle timeout, and connection timeout. Typical pool size: number of CPU cores × 2 + effective spindle count.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["databases", "connection-pool", "performance"],
  },
  {
    questionText: "What is the purpose of a reverse proxy like Nginx?",
    idealAnswer: "A reverse proxy sits in front of backend servers and forwards client requests. Benefits: load balancing across servers, SSL termination, static file serving, response caching, request buffering, rate limiting, and hiding backend architecture. Nginx is lightweight and event-driven, handling thousands of concurrent connections. In production: Nginx → Node.js app servers → Database.",
    category: "Infrastructure",
    difficulty: "EASY" as const,
    tags: ["nginx", "reverse-proxy", "infrastructure"],
  },
  {
    questionText: "What is logging best practices in backend services?",
    idealAnswer: "Use structured logging (JSON format) with consistent fields: timestamp, level, message, requestId, userId. Log levels: ERROR (failures), WARN (degraded), INFO (key events), DEBUG (details). Use a library like Winston or Pino. Include correlation IDs for request tracing. Never log sensitive data (passwords, tokens). Send logs to centralized systems (ELK, Datadog) for analysis.",
    category: "Observability",
    difficulty: "EASY" as const,
    tags: ["logging", "observability", "best-practices"],
  },
  {
    questionText: "What is the N+1 query problem?",
    idealAnswer: "N+1 occurs when you query a list (1 query) then query related data for each item (N queries). Example: fetching 100 users then 100 individual queries for their posts. Solutions: eager loading (Prisma `include`), JOIN queries, DataLoader pattern for batching. Prisma's `include` and `select` prevent N+1 by generating JOINs or batched queries.",
    category: "Databases",
    difficulty: "EASY" as const,
    tags: ["databases", "n-plus-1", "performance"],
  },
  {
    questionText: "What is rate limiting and how do you implement it?",
    idealAnswer: "Rate limiting restricts how many requests a client can make in a time window to prevent abuse and ensure fair usage. Algorithms: fixed window, sliding window, token bucket, leaky bucket. Implement with Redis counters (distributed) or express-rate-limit (single server). Return 429 Too Many Requests with `Retry-After` header. Apply different limits for authenticated vs anonymous users.",
    category: "Security",
    difficulty: "EASY" as const,
    tags: ["rate-limiting", "security", "redis"],
  },
  {
    questionText: "What is Git branching and what's a common branching strategy?",
    idealAnswer: "Git branches are lightweight pointers to commits, allowing parallel development. Common strategies: GitHub Flow (main + feature branches, PRs), GitFlow (main, develop, feature, release, hotfix), Trunk-Based (short-lived branches, frequent merges to main). GitHub Flow is simplest: create branch, commit, open PR, review, merge to main, deploy.",
    category: "Git",
    difficulty: "EASY" as const,
    tags: ["git", "branching", "workflow"],
  },
  {
    questionText: "What are the SOLID principles?",
    idealAnswer: "SOLID: Single Responsibility (one reason to change), Open/Closed (open for extension, closed for modification), Liskov Substitution (subtypes replaceable for base types), Interface Segregation (specific interfaces over general ones), Dependency Inversion (depend on abstractions, not concretions). These principles lead to maintainable, testable, and extensible code.",
    category: "Design Patterns",
    difficulty: "EASY" as const,
    tags: ["solid", "design-patterns", "architecture"],
  },

  // ===== MEDIUM (40 questions) =====
  {
    questionText: "How would you design a RESTful API for a blog platform with posts, comments, and users?",
    idealAnswer: "Resources: `/users`, `/posts`, `/posts/:id/comments`. Use proper HTTP methods: GET for reads, POST for creation, PUT/PATCH for updates, DELETE for removal. Implement pagination (`?page=1&limit=20`), filtering (`?status=published`), sorting (`?sort=-createdAt`). Return consistent response envelopes `{data, meta, errors}`. Use 201 for creation, 204 for deletion. Version with `/api/v1/`.",
    category: "APIs",
    difficulty: "MEDIUM" as const,
    tags: ["rest", "api-design", "http"],
  },
  {
    questionText: "Explain the difference between horizontal and vertical scaling. When would you use each?",
    idealAnswer: "Vertical scaling (scale up) adds more CPU/RAM to a single server — simpler but has hardware limits. Horizontal scaling (scale out) adds more servers behind a load balancer — handles more traffic, provides redundancy, but requires stateless architecture. Use vertical for databases (easier consistency), horizontal for application servers (stateless, containerized). Most production systems use both.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["scaling", "architecture", "infrastructure"],
  },
  {
    questionText: "What is database normalization? Explain the first three normal forms.",
    idealAnswer: "Normalization reduces data redundancy. 1NF: atomic values, no repeating groups (each cell has one value). 2NF: 1NF + no partial dependencies (all non-key attributes depend on the entire primary key). 3NF: 2NF + no transitive dependencies (non-key attributes don't depend on other non-key attributes). Denormalization is sometimes used for read performance, accepting controlled redundancy.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["databases", "normalization", "schema-design"],
  },
  {
    questionText: "How do database transactions work? What are ACID properties?",
    idealAnswer: "Transactions group operations into atomic units. ACID: Atomicity (all or nothing), Consistency (valid state transitions), Isolation (concurrent transactions don't interfere), Durability (committed data persists through failures). Isolation levels from weak to strong: Read Uncommitted, Read Committed, Repeatable Read, Serializable. Higher isolation = fewer anomalies but lower concurrency. PostgreSQL defaults to Read Committed.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["databases", "transactions", "acid"],
  },
  {
    questionText: "Explain the event loop in Node.js and its phases.",
    idealAnswer: "Node's event loop has phases: timers (setTimeout/setInterval), pending callbacks (I/O), idle/prepare, poll (new I/O events), check (setImmediate), close callbacks. Microtasks (Promise.then, process.nextTick) run between phases. The poll phase waits for I/O if nothing else is scheduled. Understanding this prevents blocking the loop with CPU-intensive synchronous code, which would freeze all request handling.",
    category: "Node.js",
    difficulty: "MEDIUM" as const,
    tags: ["nodejs", "event-loop", "async"],
  },
  {
    questionText: "What is GraphQL and how does it compare to REST?",
    idealAnswer: "GraphQL is a query language where clients request exactly the data they need in a single request. vs REST: no over/under-fetching, single endpoint, strongly typed schema, client-driven queries. Trade-offs: GraphQL adds complexity (resolvers, schema management), caching is harder (no HTTP caching by URL), N+1 at resolver level. Use GraphQL for complex data requirements; REST for simple CRUD APIs.",
    category: "APIs",
    difficulty: "MEDIUM" as const,
    tags: ["graphql", "api", "rest"],
  },
  {
    questionText: "How would you implement pagination in an API? Compare offset-based and cursor-based.",
    idealAnswer: "Offset-based: `?page=2&limit=20` — simple but slow on large datasets (OFFSET scans rows) and inconsistent with real-time inserts. Cursor-based: `?cursor=abc123&limit=20` uses a unique, sequential field (ID, timestamp) — `WHERE id > cursor ORDER BY id LIMIT 20`. Cursor is faster, consistent, but can't jump to arbitrary pages. Use cursor for feeds/infinite scroll, offset for admin tables with page numbers.",
    category: "APIs",
    difficulty: "MEDIUM" as const,
    tags: ["pagination", "api", "databases"],
  },
  {
    questionText: "What is a message queue and when would you use one?",
    idealAnswer: "Message queues (RabbitMQ, SQS, BullMQ) decouple producers from consumers, enabling async processing. Use cases: email sending, image processing, payment processing, inter-service communication. Benefits: load leveling (handle traffic spikes), retry on failure, service independence. Patterns: work queue (multiple consumers), pub/sub (multiple subscribers), dead letter queue (failed messages). BullMQ uses Redis for Node.js.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["message-queue", "async", "architecture"],
  },
  {
    questionText: "How do you handle file uploads securely in a backend service?",
    idealAnswer: "Security measures: validate file type (check magic bytes, not just extension), limit file size (multer limits), sanitize filenames, store outside web root or in object storage (S3/MinIO), scan for malware, generate unique filenames (UUID), set proper Content-Type and Content-Disposition headers on download. Use streaming for large files to avoid memory issues. Never execute uploaded files.",
    category: "Security",
    difficulty: "MEDIUM" as const,
    tags: ["file-upload", "security", "minio"],
  },
  {
    questionText: "What is the CAP theorem? Explain with real-world examples.",
    idealAnswer: "CAP states distributed systems can guarantee at most two of: Consistency (all nodes see same data), Availability (every request gets a response), Partition tolerance (system works despite network failures). Since partitions are inevitable, the real choice is CP or AP. MongoDB is CP (refuses writes during partition). Cassandra is AP (stays available, may serve stale data). DynamoDB offers tunable consistency per query.",
    category: "Distributed Systems",
    difficulty: "MEDIUM" as const,
    tags: ["cap-theorem", "distributed-systems", "databases"],
  },
  {
    questionText: "How do you implement caching effectively in a backend system?",
    idealAnswer: "Strategies: cache-aside (app checks cache first, loads from DB on miss), write-through (write to cache and DB simultaneously), write-behind (write to cache, async persist to DB). Cache layers: application-level (in-memory), distributed (Redis), CDN (static assets), HTTP caching (Cache-Control headers). Invalidation: TTL-based, event-driven, or versioned keys. Cache only data that's read often and changes rarely.",
    category: "Performance",
    difficulty: "MEDIUM" as const,
    tags: ["caching", "redis", "performance"],
  },
  {
    questionText: "What are microservices and when should you use them vs a monolith?",
    idealAnswer: "Microservices split an application into independently deployable services, each with its own database. Benefits: independent scaling, technology diversity, team autonomy, fault isolation. Downsides: distributed system complexity, network latency, data consistency challenges, operational overhead. Start with a monolith, extract services when team/scale demands it. Microservices are a solution for organizational scaling, not just technical scaling.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["microservices", "architecture", "monolith"],
  },
  {
    questionText: "Explain SQL injection and how to prevent it.",
    idealAnswer: "SQL injection inserts malicious SQL through user input. Example: `' OR 1=1 --` in a login form. Prevention: parameterized queries (prepared statements) — never concatenate user input into SQL. ORMs like Prisma use parameterized queries by default. Additional defenses: input validation, least-privilege DB users, WAF rules. Never use raw SQL with string interpolation for user input.",
    category: "Security",
    difficulty: "MEDIUM" as const,
    tags: ["security", "sql-injection", "databases"],
  },
  {
    questionText: "How do you implement role-based access control (RBAC)?",
    idealAnswer: "RBAC assigns permissions to roles, then roles to users. Implementation: User → UserRole → Role → RolePermission → Permission. Middleware checks: extract user from JWT, load roles, verify required permission for the endpoint. Store roles in JWT claims for stateless checks, or query DB for fine-grained control. Patterns: hierarchical roles (admin inherits editor), resource-based permissions (can_edit:post), attribute-based (ABAC) for complex rules.",
    category: "Security",
    difficulty: "MEDIUM" as const,
    tags: ["rbac", "authorization", "security"],
  },
  {
    questionText: "What is an API gateway and what functions does it serve?",
    idealAnswer: "An API gateway is a single entry point for all API requests. Functions: request routing to downstream services, authentication/authorization, rate limiting, request/response transformation, load balancing, caching, circuit breaking, logging/monitoring, API versioning. Tools: Kong, AWS API Gateway, or custom (Express proxy). Prevents clients from knowing internal service topology.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["api-gateway", "microservices", "architecture"],
  },
  {
    questionText: "How do you design a database schema for a multi-tenant application?",
    idealAnswer: "Three strategies: (1) Separate databases per tenant — best isolation, highest cost, complex management. (2) Shared database, separate schemas — good isolation, moderate complexity. (3) Shared schema with tenant_id column — simplest, lowest cost, requires careful query filtering. Most SaaS apps use shared schema with row-level security. Add `tenantId` to every table, enforce via middleware, and use PostgreSQL Row Level Security policies.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["multi-tenancy", "databases", "schema-design"],
  },
  {
    questionText: "Explain the repository and service layer patterns.",
    idealAnswer: "Repository pattern abstracts data access — provides methods like `findById`, `create`, `update` without exposing database implementation. Service layer contains business logic, orchestrates repositories, and handles transactions. Controller → Service → Repository → Database. Benefits: testable (mock repositories), swappable data sources, separation of concerns. Over-engineering risk: for simple CRUD, repositories may add unnecessary abstraction.",
    category: "Design Patterns",
    difficulty: "MEDIUM" as const,
    tags: ["design-patterns", "repository", "service-layer"],
  },
  {
    questionText: "How do you implement graceful shutdown in a Node.js server?",
    idealAnswer: "Listen for SIGTERM/SIGINT signals, stop accepting new connections, wait for in-flight requests to complete (with a timeout), close database connections and other resources, then exit. Implementation: `process.on('SIGTERM', async () => { server.close(); await prisma.$disconnect(); process.exit(0); })`. Set a timeout to force exit if cleanup takes too long. Critical for zero-downtime deployments in Kubernetes.",
    category: "Node.js",
    difficulty: "MEDIUM" as const,
    tags: ["nodejs", "graceful-shutdown", "devops"],
  },
  {
    questionText: "What is the difference between OAuth 2.0 and OpenID Connect?",
    idealAnswer: "OAuth 2.0 is an authorization framework — it grants third-party access to resources (scopes) without sharing credentials. OpenID Connect (OIDC) builds on OAuth 2.0 adding authentication — it provides an ID token (JWT) with user identity. OAuth answers 'what can this app do?'; OIDC answers 'who is the user?'. Use OIDC for login (Google Sign-In), OAuth for API access (GitHub API).",
    category: "Security",
    difficulty: "MEDIUM" as const,
    tags: ["oauth", "oidc", "authentication"],
  },
  {
    questionText: "How do you handle database connection failures and retries?",
    idealAnswer: "Implement exponential backoff with jitter: wait 1s, 2s, 4s... with random variance to prevent thundering herd. Use circuit breaker pattern: after N failures, stop trying for a cooldown period. Connection pool handles transient failures automatically. For critical operations, use idempotent retries. Log failures with context. Health checks should verify DB connectivity. Prisma has built-in connection retry logic.",
    category: "Resilience",
    difficulty: "MEDIUM" as const,
    tags: ["databases", "retry", "resilience"],
  },
  {
    questionText: "What is the circuit breaker pattern and when should you use it?",
    idealAnswer: "The circuit breaker prevents cascading failures in distributed systems. States: Closed (requests pass through), Open (requests fail immediately after threshold failures), Half-Open (limited requests to test recovery). Use it for: external API calls, database connections, inter-service communication. Libraries: opossum (Node.js). It prevents overwhelming a failing service and allows it to recover.",
    category: "Resilience",
    difficulty: "MEDIUM" as const,
    tags: ["circuit-breaker", "resilience", "patterns"],
  },
  {
    questionText: "How would you implement a search feature using PostgreSQL full-text search?",
    idealAnswer: "Use `tsvector` (document representation) and `tsquery` (search query). Create a GIN index on the tsvector column. Query: `WHERE to_tsvector('english', title || ' ' || body) @@ to_tsquery('english', 'search & terms')`. Features: stemming, ranking with `ts_rank`, language support, phrase search. For simple needs, PostgreSQL FTS is sufficient. For complex search (facets, fuzzy, suggestions), consider Elasticsearch.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["postgresql", "full-text-search", "databases"],
  },
  {
    questionText: "What is database sharding and when is it necessary?",
    idealAnswer: "Sharding horizontally partitions data across multiple database instances based on a shard key (e.g., userId range or hash). Necessary when: a single database can't handle the write volume, data exceeds single-server storage, or latency requirements need geographic distribution. Challenges: cross-shard queries, rebalancing, maintaining referential integrity. Consider read replicas and caching before sharding.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["sharding", "databases", "scaling"],
  },
  {
    questionText: "How do you implement request tracing in a microservices architecture?",
    idealAnswer: "Generate a unique trace ID at the API gateway, propagate it through all service calls via headers (e.g., `x-request-id`). Each service logs with the trace ID, enabling end-to-end request tracking. Use OpenTelemetry for standardized instrumentation. Tools: Jaeger, Zipkin for trace visualization. Include trace IDs in error responses for debugging. Collect spans with timing data for performance analysis.",
    category: "Observability",
    difficulty: "MEDIUM" as const,
    tags: ["tracing", "observability", "microservices"],
  },
  {
    questionText: "What is WebSocket and how does it differ from HTTP for real-time communication?",
    idealAnswer: "WebSocket provides full-duplex persistent connections over a single TCP connection. Unlike HTTP's request-response model, both client and server can send messages anytime. WebSocket starts with an HTTP upgrade handshake. Use cases: chat, live notifications, gaming, collaborative editing. Alternatives: Server-Sent Events (SSE) for one-way streaming, long polling for compatibility. Libraries: Socket.IO (with fallbacks), ws (raw WebSocket).",
    category: "Networking",
    difficulty: "MEDIUM" as const,
    tags: ["websocket", "real-time", "networking"],
  },
  {
    questionText: "How would you implement an email notification system?",
    idealAnswer: "Architecture: (1) Event triggers add email jobs to a message queue (BullMQ/SQS), (2) Worker processes pick up jobs and send via email provider (SendGrid, SES, Resend), (3) Use templates (Handlebars, React Email) for consistent formatting, (4) Track delivery status with webhooks, (5) Implement retry with backoff for failures, (6) Rate limit to avoid provider throttling, (7) Batch similar notifications to reduce noise.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["email", "queue", "notifications"],
  },
  {
    questionText: "What is Prisma and how does it compare to traditional ORMs like Sequelize?",
    idealAnswer: "Prisma is a modern ORM with: type-safe client generated from schema, declarative schema language, visual database browser (Prisma Studio), and migration system. vs Sequelize: Prisma has better TypeScript support, schema-first approach, and simpler relation queries. Prisma generates SQL from a schema file; Sequelize defines models in code. Prisma's `include` prevents N+1 queries. Trade-off: Prisma is less flexible for complex raw SQL.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["prisma", "orm", "databases"],
  },
  {
    questionText: "How do you write effective unit tests for backend services?",
    idealAnswer: "Principles: test behavior not implementation, one assertion focus per test, arrange-act-assert pattern. Mock external dependencies (DB, APIs) with jest.mock or dependency injection. Test edge cases: empty inputs, errors, boundary values. Structure: unit tests (fast, isolated), integration tests (with real DB), e2e tests (full API). Aim for high coverage on business logic, not on framework boilerplate.",
    category: "Testing",
    difficulty: "MEDIUM" as const,
    tags: ["testing", "jest", "unit-tests"],
  },
  {
    questionText: "What is the difference between optimistic and pessimistic locking?",
    idealAnswer: "Pessimistic locking locks the record during the entire read-modify-write cycle (`SELECT ... FOR UPDATE`). No other transaction can modify it. Safe but reduces concurrency. Optimistic locking adds a version/timestamp column; on update, check if the version matches. If not, the record was modified — retry or fail. Optimistic is better for low-contention scenarios; pessimistic for high-contention.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["databases", "locking", "concurrency"],
  },
  {
    questionText: "How do you handle secrets management in production environments?",
    idealAnswer: "Never store secrets in code or Git. Use: environment variables via orchestrator (Docker/Kubernetes secrets), secret managers (AWS Secrets Manager, HashiCorp Vault), encrypted config files. Rotate secrets regularly. Use service accounts with minimal permissions. In Kubernetes: mount secrets as volumes or env vars. Audit secret access. For development: `.env` files in `.gitignore` with `.env.example` templates.",
    category: "Security",
    difficulty: "MEDIUM" as const,
    tags: ["secrets", "security", "devops"],
  },
  {
    questionText: "Explain the Saga pattern for distributed transactions.",
    idealAnswer: "Saga manages distributed transactions as a sequence of local transactions with compensating actions. Two types: Choreography (events trigger next steps) and Orchestration (central coordinator directs flow). Example: order service → payment service → inventory service; if inventory fails, compensate by refunding payment and canceling order. Each step must be idempotent. Use for: multi-service operations that can't use traditional ACID transactions.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["saga", "distributed-transactions", "microservices"],
  },
  {
    questionText: "How would you implement a background job processing system?",
    idealAnswer: "Use BullMQ (Redis-backed) for Node.js: define queues, add jobs with data, process with worker functions. Features: job priority, delayed jobs, retries with backoff, job progress, rate limiting, named processors. Monitor with Bull Board dashboard. For distributed systems: multiple workers consume from the same queue. Handle failures gracefully with dead letter queues. Common jobs: email sending, report generation, data imports.",
    category: "Architecture",
    difficulty: "MEDIUM" as const,
    tags: ["background-jobs", "bullmq", "queues"],
  },
  {
    questionText: "What are database views and materialized views? When would you use them?",
    idealAnswer: "A view is a virtual table defined by a query — computed on each access, always up-to-date. A materialized view stores the query result physically — faster reads but needs explicit refresh. Use views for: simplifying complex joins, access control (expose limited columns). Use materialized views for: expensive aggregations, reporting dashboards, read-heavy analytics. PostgreSQL supports both with `CREATE [MATERIALIZED] VIEW`.",
    category: "Databases",
    difficulty: "MEDIUM" as const,
    tags: ["databases", "views", "postgresql"],
  },
  {
    questionText: "How do you monitor and alert on backend service health?",
    idealAnswer: "Implement: (1) Health check endpoints (`/health`, `/ready`) checking DB, Redis, external services, (2) Metrics collection (Prometheus) — request rate, error rate, latency percentiles, (3) Structured logging (JSON to ELK/Datadog), (4) Alerts on: error rate > threshold, latency P99 spike, disk/memory usage, (5) Dashboards (Grafana) for visualization, (6) On-call rotation with PagerDuty. Follow the RED method: Rate, Errors, Duration.",
    category: "Observability",
    difficulty: "MEDIUM" as const,
    tags: ["monitoring", "observability", "prometheus"],
  },
  {
    questionText: "What is TypeScript's type system and how does it help in backend development?",
    idealAnswer: "TypeScript adds static typing to JavaScript: interfaces, generics, union/intersection types, enums, and type inference. Backend benefits: catch errors at compile time (wrong argument types, missing fields), self-documenting APIs, safer refactoring, IDE support (autocomplete, go-to-definition). Prisma generates types from schema, ensuring DB queries are type-safe. Zod validates runtime types matching TypeScript definitions.",
    category: "TypeScript",
    difficulty: "MEDIUM" as const,
    tags: ["typescript", "type-safety", "backend"],
  },
  {
    questionText: "How do you implement API versioning?",
    idealAnswer: "Strategies: (1) URL path (`/api/v1/users`) — most common, explicit, cacheable, (2) Header-based (`Accept: application/vnd.api.v2+json`) — cleaner URLs but harder to test, (3) Query parameter (`?version=2`) — simple but not RESTful. Best practices: support at least one prior version, communicate deprecation timelines, use semantic versioning internally. Route different versions to different handlers or apply transformation middleware.",
    category: "APIs",
    difficulty: "MEDIUM" as const,
    tags: ["api-versioning", "rest", "api"],
  },

  // ===== HARD (30 questions) =====
  {
    questionText: "How would you design a system that handles 10,000 concurrent WebSocket connections?",
    idealAnswer: "Architecture: (1) Use a WebSocket server (ws, Socket.IO) with event-driven model — Node.js handles many concurrent connections well, (2) Horizontal scaling with Redis pub/sub or Redis Streams for cross-server message broadcasting, (3) Sticky sessions or separate connection state service, (4) Connection pooling and heartbeat/ping for stale connection cleanup, (5) Backpressure handling for slow clients, (6) Load balancer with WebSocket support (HAProxy, ALB). Single Node process can handle ~10K connections; scale horizontally beyond that.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["websocket", "scaling", "architecture"],
  },
  {
    questionText: "Explain database query optimization techniques with PostgreSQL.",
    idealAnswer: "Techniques: (1) Use `EXPLAIN ANALYZE` to understand query plans, (2) Add indexes on WHERE, JOIN, ORDER BY columns, (3) Use composite indexes for multi-column queries, (4) Avoid `SELECT *` — select only needed columns, (5) Use covering indexes (INCLUDE), (6) Partition large tables by date/range, (7) Optimize JOINs with proper index support, (8) Use CTEs and window functions instead of subqueries, (9) Vacuum and analyze regularly, (10) Consider partial indexes for common WHERE conditions. Monitor with `pg_stat_statements`.",
    category: "Databases",
    difficulty: "HARD" as const,
    tags: ["postgresql", "query-optimization", "performance"],
  },
  {
    questionText: "Design a rate limiter that works across a distributed system.",
    idealAnswer: "Use Redis with sliding window algorithm: store timestamps in a sorted set per key, remove entries outside the window, count remaining. Alternatively, use token bucket with Redis MULTI/EXEC for atomicity. Handle: per-user, per-IP, per-endpoint limits. Use Lua scripts in Redis for atomic increment-and-check. Consider: race conditions, clock skew between nodes, failover behavior. Return `429` with `Retry-After` header and `X-RateLimit-*` headers for remaining quota.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["rate-limiting", "redis", "distributed-systems"],
  },
  {
    questionText: "How would you implement a distributed cache invalidation strategy?",
    idealAnswer: "Strategies: (1) TTL-based expiration (simple, eventual consistency), (2) Event-driven invalidation via pub/sub — DB change triggers cache delete across all nodes, (3) Write-through: update cache on every write, (4) Versioned keys (`user:123:v5`) — new version = new key, old TTLs expire naturally, (5) Cache-aside with short TTL for stale tolerance. For multi-region: use Redis Cluster or cache-per-region with cross-region pub/sub. Always design for cache failures — the app should work (slower) without cache.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["caching", "distributed-systems", "redis"],
  },
  {
    questionText: "Explain how you would implement end-to-end encryption for a messaging feature.",
    idealAnswer: "Use Signal Protocol or similar: (1) Each user generates asymmetric key pair (Ed25519), stores private key client-side, (2) Public keys registered on server, (3) Sender encrypts message with recipient's public key, (4) Server stores only ciphertext — cannot read messages, (5) Key exchange via X3DH (Extended Triple Diffie-Hellman), (6) Forward secrecy with ratcheting (each message uses a new key), (7) Group messaging with Sender Keys. Server handles delivery and storage of encrypted blobs only.",
    category: "Security",
    difficulty: "HARD" as const,
    tags: ["encryption", "security", "messaging"],
  },
  {
    questionText: "How would you design a notification system that supports multiple channels (email, push, SMS)?",
    idealAnswer: "Architecture: (1) Notification service receives events from other services, (2) Channel router determines delivery channels based on user preferences and notification type, (3) Each channel has a dedicated queue and worker (email worker, push worker, SMS worker), (4) Template engine renders content per channel, (5) Delivery tracking with status webhooks, (6) Rate limiting and batching to prevent notification fatigue, (7) Priority levels (urgent = immediate, normal = batched), (8) Unsubscribe management per channel/type. Use event sourcing for audit trail.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["notifications", "architecture", "queues"],
  },
  {
    questionText: "What is event sourcing and how does it differ from traditional CRUD?",
    idealAnswer: "Event sourcing stores state changes as an immutable sequence of events rather than overwriting current state. To get current state, replay events. Benefits: complete audit trail, temporal queries (state at any point), event-driven architectures, undo/redo. Challenges: event schema evolution, eventual consistency, complex read queries (solved with CQRS — separate read/write models). Use for: financial systems, audit requirements, collaborative editing. Overkill for simple CRUD apps.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["event-sourcing", "cqrs", "architecture"],
  },
  {
    questionText: "How do you implement zero-downtime deployments?",
    idealAnswer: "Strategies: (1) Blue-green: two identical environments, switch traffic after verification, (2) Rolling update: gradually replace instances (Kubernetes default), (3) Canary: route small percentage to new version, monitor, gradually increase. Requirements: backward-compatible DB migrations (add columns before code, remove after), graceful shutdown (drain connections), health checks, rollback plan. Database: use expand-contract pattern — never remove/rename columns in the same deploy as code changes.",
    category: "DevOps",
    difficulty: "HARD" as const,
    tags: ["deployment", "zero-downtime", "devops"],
  },
  {
    questionText: "Design a job scheduling system that handles millions of scheduled tasks.",
    idealAnswer: "Architecture: (1) Scheduler stores jobs in a database with next_run_at indexed column, (2) Poller queries for due jobs using `SELECT ... FOR UPDATE SKIP LOCKED` (PostgreSQL) to prevent duplicate processing, (3) Distribute execution to worker pool via Redis queue, (4) Support cron expressions and one-time schedules, (5) Handle: missed schedules (catch-up vs skip), job deduplication, timezone handling, (6) Partitioned table by next_run_at for efficient polling. Alternatives: Temporal.io for complex workflows, pg-boss for PostgreSQL-native.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["scheduling", "distributed-systems", "architecture"],
  },
  {
    questionText: "Explain how to implement a search engine with relevance ranking.",
    idealAnswer: "Core components: (1) Inverted index mapping terms to documents, (2) Tokenization and normalization (lowercasing, stemming, stop words), (3) TF-IDF or BM25 scoring for relevance ranking, (4) Query parsing (boolean operators, phrases, fuzzy matching), (5) Faceted search with aggregations, (6) Autocomplete with prefix trees or n-gram indexes. For production: use Elasticsearch/OpenSearch. Index pipeline: ingest → analyze → index → query → rank. Optimize with: field boosting, synonyms, custom analyzers.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["search", "elasticsearch", "algorithms"],
  },
  {
    questionText: "How would you handle data consistency across microservices?",
    idealAnswer: "Patterns: (1) Saga pattern — choreographed or orchestrated sequence of local transactions with compensating actions, (2) Outbox pattern — write events to a local outbox table in the same transaction, then publish asynchronously (prevents dual-write problem), (3) Event sourcing — derive state from events, (4) Two-phase commit (2PC) — rarely used due to blocking and coordinator failure risks. Embrace eventual consistency where possible. Use idempotent operations and correlation IDs for reliability.",
    category: "Distributed Systems",
    difficulty: "HARD" as const,
    tags: ["consistency", "microservices", "saga"],
  },
  {
    questionText: "How do you implement database connection management for a high-traffic application?",
    idealAnswer: "Strategies: (1) Connection pooling with optimal pool size (connections = CPU cores × 2 + spindle count), (2) PgBouncer as an external connection pooler for serverless/high-connection scenarios, (3) Read replicas for read-heavy workloads, (4) Connection timeout and idle timeout configuration, (5) Health checks on pooled connections, (6) Statement-level connection borrowing vs session-level. Monitor: active connections, wait time, connection errors. In Prisma, configure `connection_limit` in the connection URL.",
    category: "Databases",
    difficulty: "HARD" as const,
    tags: ["databases", "connection-pool", "performance"],
  },
  {
    questionText: "Design an audit logging system for a compliance-critical application.",
    idealAnswer: "Requirements: immutability, completeness, searchability. Implementation: (1) Middleware captures all state-changing operations with who/what/when/from-where, (2) Append-only audit table with write-only permissions (no UPDATE/DELETE), (3) Include: userId, action, resource, old/new values (JSON diff), IP, user agent, timestamp, (4) Separate audit DB or schema to prevent accidental deletion, (5) Digital signatures or hash chains for tamper detection, (6) Retention policies with archival to cold storage. Query with: Elasticsearch for search, TimescaleDB for time-series analysis.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["audit-logging", "compliance", "security"],
  },
  {
    questionText: "Explain the outbox pattern and why it solves the dual-write problem.",
    idealAnswer: "The dual-write problem: writing to a DB and publishing an event aren't atomic — one can succeed while the other fails, causing inconsistency. The outbox pattern: write the event to an 'outbox' table in the same DB transaction as the business data. A separate process (CDC with Debezium, or polling) reads the outbox and publishes events to the message broker. This guarantees at-least-once delivery without distributed transactions.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["outbox-pattern", "event-driven", "consistency"],
  },
  {
    questionText: "How would you implement a multi-region database architecture?",
    idealAnswer: "Options: (1) Single primary with read replicas in each region — simple but write latency for remote regions, (2) Multi-primary (CockroachDB, Spanner) — low latency everywhere but complex conflict resolution, (3) Active-passive with failover — one region handles writes, others are standby, (4) Data partitioning by region — users route to nearest region, data stays local. Challenges: conflict resolution, compliance (data residency), failover testing, cross-region consistency. Use CRDTs for conflict-free replication where possible.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["multi-region", "databases", "architecture"],
  },
  {
    questionText: "How do you detect and prevent DDoS attacks at the application level?",
    idealAnswer: "Application-level (Layer 7) defenses: (1) Rate limiting per IP, user, and endpoint, (2) CAPTCHA challenges for suspicious traffic, (3) Request fingerprinting (headers, timing patterns), (4) Adaptive rate limits based on server load, (5) Bot detection with JavaScript challenges, (6) Geographic blocking for unexpected traffic sources, (7) Request queuing with priority for authenticated users. Infrastructure: WAF (CloudFlare, AWS WAF), auto-scaling, CDN for static content. Always have a runbook for DDoS incidents.",
    category: "Security",
    difficulty: "HARD" as const,
    tags: ["ddos", "security", "rate-limiting"],
  },
  {
    questionText: "Design an idempotent payment processing system.",
    idealAnswer: "Idempotency ensures duplicate requests produce the same result. Implementation: (1) Client generates idempotency key (UUID) sent in header, (2) Server checks key in DB before processing, (3) Store key + result in same transaction as payment, (4) Return cached result for duplicate keys, (5) TTL on idempotency keys (24-48 hours), (6) State machine for payment lifecycle (pending → processing → completed/failed), (7) Distributed lock during processing to prevent concurrent duplicates. Handle: network timeouts, payment gateway retries, webhook deduplication.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["idempotency", "payments", "architecture"],
  },
  {
    questionText: "How would you implement a feature flag system?",
    idealAnswer: "Architecture: (1) Feature flags stored in DB/config service with: name, enabled, percentage rollout, user targeting rules, (2) SDK evaluates flags per request with caching, (3) Types: boolean toggle, percentage rollout, user-segment targeting, (4) Admin UI for flag management, (5) Audit log for all changes, (6) Stale flag cleanup process, (7) SDK-level caching with polling or SSE updates. Use for: gradual rollouts, A/B testing, kill switches, trunk-based development. Tools: LaunchDarkly, Unleash, or custom.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["feature-flags", "architecture", "deployment"],
  },
  {
    questionText: "Explain how to implement a robust retry mechanism with exponential backoff.",
    idealAnswer: "Implementation: (1) Base delay with exponential growth: `delay = min(baseDelay * 2^attempt, maxDelay)`, (2) Add jitter: `delay = random(0, calculatedDelay)` to prevent thundering herd, (3) Max retry count with circuit breaker, (4) Idempotent operations only (non-idempotent = dangerous retries), (5) Distinguish retryable (503, timeout, network error) from non-retryable (400, 401) errors, (6) Log each retry with context, (7) Respect `Retry-After` headers. Use libraries: async-retry, axios-retry, or built-in queue retry in BullMQ.",
    category: "Resilience",
    difficulty: "HARD" as const,
    tags: ["retry", "backoff", "resilience"],
  },
  {
    questionText: "How would you design a file storage service that handles petabytes of data?",
    idealAnswer: "Architecture: (1) Object storage (S3, MinIO) for files — not filesystem, (2) Content-addressed storage (hash-based paths) for deduplication, (3) Chunked uploads with resumability (tus protocol), (4) Multi-tier storage: hot (SSD/S3), warm (S3-IA), cold (Glacier) based on access patterns, (5) CDN for frequently accessed files, (6) Metadata DB for file records with S3 keys, (7) Virus scanning on upload, (8) Lifecycle policies for automatic archival/deletion. Signed URLs for secure direct downloads bypassing the application server.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["file-storage", "s3", "architecture"],
  },
  {
    questionText: "What is the bulkhead pattern and how does it improve system resilience?",
    idealAnswer: "The bulkhead pattern isolates system components so a failure in one doesn't cascade to others — like ship compartments preventing flooding. Implementation: (1) Separate thread/connection pools per dependency, (2) Separate circuit breakers per external service, (3) Resource limits per tenant/feature, (4) Queue isolation for different job types. Example: if the payment service pool is exhausted, the user service pool is unaffected. Combine with circuit breaker and timeout patterns for comprehensive resilience.",
    category: "Resilience",
    difficulty: "HARD" as const,
    tags: ["bulkhead", "resilience", "patterns"],
  },
  {
    questionText: "Design a real-time analytics pipeline for tracking user events.",
    idealAnswer: "Architecture: (1) Client SDKs send events to an ingestion API, (2) Kafka/Kinesis for high-throughput event streaming, (3) Stream processing (Flink, Kafka Streams) for real-time aggregation, (4) Time-series DB (TimescaleDB, ClickHouse) for storage, (5) Batch processing (Spark) for historical analysis, (6) Redis for real-time counters and leaderboards, (7) Grafana dashboards for visualization. Lambda architecture: real-time stream layer + batch layer for correctness. Handle: late events, deduplication, schema evolution.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["analytics", "streaming", "kafka"],
  },
  {
    questionText: "How do you implement database migrations in production without downtime?",
    idealAnswer: "Expand-contract pattern: Phase 1 (expand): add new column, dual-write to both old and new, backfill existing data. Phase 2 (migrate): update code to read from new column. Phase 3 (contract): remove old column in a later deploy. Rules: never rename columns in the same deploy as code, always add with DEFAULT, use concurrent index creation (PostgreSQL `CREATE INDEX CONCURRENTLY`), test migrations on production-sized datasets. Prisma: preview migrations before applying.",
    category: "DevOps",
    difficulty: "HARD" as const,
    tags: ["migrations", "zero-downtime", "databases"],
  },
  {
    questionText: "How would you implement a recommendation engine for a content platform?",
    idealAnswer: "Approaches: (1) Collaborative filtering — users who liked X also liked Y (user-user or item-item similarity), (2) Content-based — recommend items similar to what the user liked (TF-IDF on features), (3) Hybrid — combine both, (4) Matrix factorization (SVD) for latent features. Implementation: precompute recommendations in batch (Spark), store in Redis for fast retrieval. Real-time signals (recent clicks) boost recent interests. Evaluate with A/B tests on metrics: CTR, engagement time, diversity.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["recommendations", "algorithms", "architecture"],
  },
  {
    questionText: "Explain how to handle long-running requests in a REST API.",
    idealAnswer: "Pattern: (1) Accept the request, return 202 Accepted with a job ID and status URL, (2) Process asynchronously (queue worker), (3) Client polls status endpoint or subscribes to webhook/SSE for completion, (4) Status endpoint returns: pending/processing/completed/failed with progress percentage, (5) On completion, provide result URL. Implementation: BullMQ for job processing, Redis for status tracking. Include ETA and cancellation endpoint. This prevents HTTP timeouts and keeps the API responsive.",
    category: "APIs",
    difficulty: "HARD" as const,
    tags: ["async-api", "long-running", "architecture"],
  },
  {
    questionText: "How would you design a permission system more flexible than RBAC?",
    idealAnswer: "Use ABAC (Attribute-Based Access Control): evaluate policies based on subject attributes (role, department), resource attributes (owner, sensitivity), action, and environment (time, IP). Implementation: policy engine (Open Policy Agent/Oso) evaluates rules like `allow if user.department == resource.department AND user.role >= 'editor'`. Combine with RBAC: roles provide base permissions, ABAC adds contextual rules. Store policies as code, version-controlled. Cache evaluation results for performance.",
    category: "Security",
    difficulty: "HARD" as const,
    tags: ["authorization", "abac", "security"],
  },
  {
    questionText: "How do you handle data migration from a monolithic to a microservices architecture?",
    idealAnswer: "Strategy: (1) Identify bounded contexts and data ownership, (2) Strangler fig pattern — gradually extract services while monolith remains, (3) Shared database phase → database-per-service (use CDC for sync during transition), (4) Implement API contracts between services, (5) Data sync with change data capture (Debezium) during migration, (6) Feature flags to switch traffic between old and new, (7) Run both in parallel with comparison testing, (8) Migrate reads first, then writes. Never big-bang — always incremental with rollback capability.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["microservices", "migration", "architecture"],
  },
  {
    questionText: "Design a system for handling webhook delivery with guaranteed at-least-once delivery.",
    idealAnswer: "Architecture: (1) Event triggers add webhook job to durable queue (not fire-and-forget), (2) Worker delivers with timeout, (3) Verify response (2xx = success), (4) Retry with exponential backoff on failure (1min, 5min, 30min, 2h, 8h), (5) Sign payload with HMAC-SHA256 for verification, (6) Include idempotency key in payload so receivers can deduplicate, (7) Dead letter queue after max retries, (8) Webhook management UI showing delivery history and retry status, (9) IP allowlisting, (10) Circuit breaker per endpoint to stop hammering failed endpoints.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["webhooks", "reliability", "architecture"],
  },
  {
    questionText: "What is the sidecar pattern in microservices and when should you use it?",
    idealAnswer: "The sidecar pattern deploys a helper process alongside the main service in the same pod/container group. It handles cross-cutting concerns: service mesh proxy (Envoy/Istio for mTLS, routing, observability), log aggregation, configuration syncing, health monitoring. Benefits: language-agnostic, separation of concerns, consistent infrastructure across services. Use when: multiple services need the same infrastructure features, or when you can't modify service code. Trade-off: resource overhead per pod.",
    category: "Architecture",
    difficulty: "HARD" as const,
    tags: ["sidecar", "service-mesh", "microservices"],
  },
  {
    questionText: "How would you implement a custom authentication system with refresh token rotation?",
    idealAnswer: "Implementation: (1) Login returns short-lived access token (15min) + long-lived refresh token (7 days), (2) Store refresh token hash in DB (not the token itself), (3) On token refresh: invalidate old refresh token, issue new pair (rotation), (4) Detect refresh token reuse — if an old token is used, invalidate all tokens for that user (potential theft), (5) Store tokens in httpOnly, secure, sameSite cookies, (6) Access token is JWT (stateless validation), refresh token is opaque (DB lookup), (7) Device/session tracking for 'sign out everywhere'. Family-based rotation detects token theft.",
    category: "Security",
    difficulty: "HARD" as const,
    tags: ["authentication", "jwt", "security"],
  },
];
